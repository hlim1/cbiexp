This section presents the algorithm that we have developed for
isolating bugs in programs where multiple bugs are present
simultaneously.  As discussed in \Autoref{sec:background}, our
approach is to count the number of times we observe pre-specified
predicates at each program point to be true during program
execution.
%Because our system has no \textit{a priori} knowledge of
%what bugs may be in the program, or even any model of what the program
%does, our strategy is to make the set of predicates large in the
%expectation that if the predicate set covers enough facets of the
%program, every bug will be correlated with some predicate in the set.

Our instrumentation strategies generate very large sets
of predicates; in a typical application tens of thousands of distinct
predicates are randomly sampled during program execution.  Because the
number of distinct bugs in a program is (hopefully!) orders of
magnitude smaller than the number of instrumented predicates, the
algorithmic problem is at least as much about discarding irrelevant
predicates as it is about identifying relevant predicates.  This
observation is reflected in our algorithm, which consists of two phases:
\begin{enumerate}
\item Eliminate predicates that are not predictive of program failure.

\item Rank the predicates that remain.  The higher a predicate is ranked,
the more confident we are that is involved in a bug.
\end{enumerate}

Consider the following C code fragment, which we use to motivate and illustrate
our technique:
\begin{quote}
\begin{verbatim}
f = ...;          (a)
if (f == NULL) {  (b)
        x = 0;    (c)
        *f;       (d)
}
\end{verbatim}
\end{quote}
Consider the predicate {\tt f == NULL} at line {\tt (b)}, which would
be captured by our branches instrumentation scheme.  Clearly
this predicate is highly correlated with failure; in fact, whenever it
is true this program inevitably crashes.  An important observation,
however, is that even a ``smoking gun'' such as {\tt f == NULL} at
line {\tt (b)} cannot be a perfect predictor of failure when there are
multiple bugs in the program---since there are other bugs, the program can fail
even if the predicate is false.  Put another way, we assume
that bugs are independent, and there is no reason to believe that
a predicate that is a good predictor for one bug is at all correlated
with any other bug.

The bug in the code fragment above is \termdef{deterministic} with
respect to {\tt f == NULL}: if {\tt f == NULL} is true at line {\tt
(b)}, the program is guaranteed to eventually fail.  In many cases it
is simply impossible to observe the exact conditions that cause
failure; for example, buffer overrun bugs in a C program may or may
not cause the program to crash depending on runtime system decisions
about how data is laid out in memory.  Such bugs are
\termdef{non-deterministic} with respect to every predicate that we instrument:
even for the best predictor $P$, it is possible that $P$ is true and
still the program terminates normally.  In the example above, if we insert before line
{\tt (d)} a valid pointer  assignment to {\tt f} controlled by a conditional that is true
at least some of the time (say via a call to a random number generator):
\begin{quote}
\begin{verbatim}
if (random()) f = ... some valid pointer ...;
*f;
\end{verbatim}
\end{quote}
then the bug becomes non-deterministic.

To summarize, even for predicates that truly are the causes of bugs, we can neither assume that
when the predicate is true that
the program fails nor that when the predicate is false that
the program succeeds. But we can express the probability that a predicate
being true implies failure.  Let $\fail$ be an atomic predicate that is
true for failing runs and false for successful runs.  We want to compute:
\[ \crash(P) \equiv \prob(P \Rightarrow \fail) \]
for every predicate $P$ over the set of all runs.  Let $S(P)$ be the number
of successful runs in which $P$ is observed to be true at least once, and let $F(P)$ be the number of
failing runs in which $P$ is observed to be true at least once.  Then we have
\[ \crash(P) = \frac{F(P)}{S(P) + F(P)} \]

Notice that $\crash(P)$ is not affected by the set of runs in which
$P$ is observed to be false.  Thus, if $P$ is the cause of a bug, the
causes of other independent bugs do not affect $\crash(P)$.
Also note that runs in which $P$ is not observed at all (either because
the line of code on which $P$ is checked is not reached, or the line is reached
but $P$ is not sampled) have no effect on $\crash(P)$.
Finally, observe that the definition of $\crash(P)$
generalizes the idea of deterministic and non-deterministic bugs.  A
bug is deterministic for $P$ if $\crash(P) = 1.0$ or, equivalently,
$P$ is never observed to be true in a successful run ($S(P) =
0$) and $P$ is observed to be true in at least one failing run ($F(P) > 0$).
If $\crash(P) < 1.0$ then the bug is non-deterministic, with
lower scores showing weaker correlation between the predicate and
program failure.

As we shall show, $\crash(P)$ is a useful measure, but it is not good
enough for step (1) of our algorithm. To see this, consider again the
code fragment given above (in its original form, not with the
modification to make the bug non-deterministic).  At line {\tt (b)} we
have $\crash(\mbox{\tt f == NULL}) = 1.0$, so this predicate is a good
candidate for the cause of the bug.
But on line {\tt (c)} we have the surprising fact that $\crash(\mbox{\tt x == 0}) = 1.0$ as well.
To understand why, observe that the scalar-pairs instrumentation
predicate \texttt{x == 0} is always true at line {\tt (c)} and, in
addition,
only failing runs reach this line.
Thus $S(\mbox{\tt x == 0}) = 0$, and, so long as there is at least one run that
reaches line {\tt (c)} at all, $\crash(\mbox{\tt x == 0})$ at line {\tt (c)} is 1.0.

As the predicate {\tt x == 0} at line {\tt (c)} of the example
shows, just because a predicate has a high $\crash(\ldots)$ score does not
mean it is the cause of a bug.  In the case of {\tt x == 0}, the
decision that eventually causes the crash is made earlier, and the
high $\crash(\ldots)$ score of {\tt x == 0} merely reflects the fact that this
predicate is checked on a path where the program is already doomed.

One way to address this difficulty is to score a predicate not by the chance
that it implies failure, but by how much difference it makes that the predicate
is observed to be true versus simply reaching the line where the predicate is checked.
That is, on line {\tt (c)}, the probability of crashing is already 1.0 regardless
of the value of the predicate {\tt x == 0}, and thus the fact that {\tt x == 0} is
true does not increase the probability of failure at all; this coincides with
the intuition that this predicate is irrelevant to the bug.

This leads us to the following definition:
\[ \context(P) \equiv \prob((P \lor \lnot P) \Rightarrow \fail) \]
Now, $P \lor \lnot P$ is not the set of all runs, because we are not working in a two-valued logic.
In any given run, neither of $P$ or $\lnot P$ may be observed (because the site where this predicate is
sampled is not reached), or one may be observed, or both may be observed (because the statement is executed
multiple times and $P$ is sometimes true and sometimes false).  Thus, $\context(P)$ is the probability that
in the set of runs where the value of $P$ is observed at all, the program fails. We can compute $\context(P)$ as follows:
\[ \context(P) = \frac{F(P \lor \lnot P)}{S(P \lor \lnot P) + F(P \lor \lnot P)} \]

The interesting quantity, then, is
\begin{equation*}
 \increase(P) \equiv \crash(P) - \context(P) \label{eqn:1}
\end{equation*}
%%
which can be read as: How much does $P$ being true increase the probability of failure
over simply reaching the line where $P$ is sampled?  For example, for the predicate {\tt x == 0} on line {\tt (c)},
we have
\[\crash(\mbox{\tt x == 0}) = \context(\mbox{\tt x == 0}) = 1.0 \]
and so $\increase(\mbox{\tt x == 0}) = 0$.
We can now state our algorithm:
\begin{enumerate}
\item Discard any predicate $P$ where $\increase(P) \leq 0$.

\item Sort the remaining predicates lexicographically first by $\crash(P)$ and then by $\context(P)$.
\end{enumerate}

A few comments on this algorithm are in order.  First, pruning
predicates using $\increase(P) \leq 0$ has many desirable
properties.  It is easy to prove that large classes of irrelevant
predicates always have scores $\leq 0$.  For example, any predicate
that is not reached, that is a program invariant, or that is obviously
control-dependent on a true cause is eliminated by this test.  It is
also worth pointing out that this algorithm tends to localize bugs at
a point where the condition that causes the bug becomes true, rather than at
the crash site.  For example, in the code fragment given above, the bug is
attributed to the success of the conditional branch test {\tt f ==
NULL} on line {\tt (b)} rather than the pointer dereference on line
{\tt (d)}.  Thus, the cause of the bug discovered by the algorithm
points directly to the conditions under which the crash occurs, rather than
the line on which it occurs (which is usually available anyway in the
stack trace). \Autoref{sec:experiments:results} gives several examples
of this phenomenon while hunting for real bugs.

The purpose of sorting the surviving predicates in step (2) by
$\crash(\ldots)$ is to ensure that the highest confidence predicates (those
most likely to actually cause crashes) are listed first in the final
result.  We need step (2) because while $\increase(\ldots)$ is very good at
eliminating unimportant predicates, it is rather poorer as a measure
of the most important predicates.  Consider line {\tt (a)} in the
example above.  If {\tt (a)} has, say, a 90\% probability of assigning
a {\tt NULL} pointer to {\tt f}, then the value of
$\increase(\mbox{\tt f == NULL})$ will be be high at line {\tt (a)}
and lower, but still positive, at line {\tt (b)}.  While both {\tt
(a)} and {\tt (b)} contribute to the bug, it is our experience that,
once irrelevant predicates are discarded, it is most natural to
associate a bug with the predicate that gives the highest absolute
chance of failure; these are most likely to be the true causes.  For
instance, in our example, something is certainly wrong by the time we
reach line {\tt (b)}, where taking the true branch leads to a certain
crash, while it is entirely possible that line {\tt (a)} is correct.
Most likely the bug is a typographical error: the programmer meant to
write {\tt f != NULL} as the predicate of the conditional instead of
{\tt f == NULL}.

Finally, it should be clear that the algorithm is efficient.
Step (1) requires only a single pass over the data, and step (2) is
simply sorting.

\subsection{Statistical Interpretation}

The selection criterion of $\increase(P) > 0$ is equivalent to a simplified
statistical hypothesis test.  Consider the two classes of trial runs
of the program: failed runs $F$ and successful runs $S$.  For each
class, we can treat the predicate $P$ as a Bernoulli random variable
with heads probabilities $\pi_f(P)$ and $\pi_s(P)$, respectively, for the
two classes.  The heads
probability is the probability that the predicate is observed to be
true.  If a predicate causes a set of crashes, then $\pi_f$ should be
much bigger than $\pi_s$.  We can formulate two statistical hypotheses:
the null hypothesis $\H_0:
\pi_f \leq \pi_s$, vs.\ the alternate hypothesis $\H_1: \pi_f > \pi_s$.  Since
$\pi_f$ and $\pi_s$ are not known, we have to estimate them from our
data.
\begin{align*}
  \hat \pi_f(P) &= \frac{F(P)}{F(P \lor \lnot P)} &
  \hat \pi_s(P) &= \frac{S(P)}{S(P \lor \lnot P)}
\end{align*}

Although these proportion estimates of $\pi_f$ and $\pi_s$ approach the
true heads probabilities as we increase the number of trial runs, they
still differ from the true values.  With a certain probability, using these
estimates instead of the true values will give us the wrong
answer.  The \textit{Z test} takes into account this uncertainty, and
makes use of the statistic $ Z = \frac{(\hat \pi_f - \hat
  \pi_s)}{V_{f,s}}$, where $V_{f,s}$ is a sample variance term, and $Z$
is distributed as a standard Gaussian random
variable.  Performed independently for each predicate $P$, the test
decides whether or not $\pi_f(P) \leq \pi_s(P)$ with a guanranted
false-positive probability (i.e. choosing $\H_1$ when $\H_0$ is true).
A necessary (but not sufficient) condition for choosing $\H_1$ is that
$\hat \pi_f(P) > \hat \pi_s(P)$.  This turns out to be
equivalent to the condition that $\increase(P) > 0$.  To see this,
let $a = F(P)$, $b = S(P)$, $c = F(P\lor\lnot P)$, and $d = S(P\lor\lnot P)$.
Then
\begin{gather*}
  \increase(P) > 0 \iff \crash(P) > \context(P) \\
  \iff \frac{a}{a+b} > \frac{c}{c+d}
  \iff a (c+d) > (a+b) c \\
  \iff ad > bc \iff \frac{a}{c} > \frac{b}{d}
  \iff \hat \pi_f > \hat \pi_s
\end{gather*}

Hence the $\increase(P) > 0$ criterion is not only well motivated
from the program analysis point of view, but can also be seen as a much
simplified version of the Z test for two populations of
Bernoulli trials.

\subsection{Comparison with Previous Approach}
In earlier work \cite{PLDI`03*141,Zheng:2003:SDSP}
we made use of $\ell_1$-regularized logistic regression and similar
methods to select and rank the predicates in the order of their
failure-prediction strength.  This approach proves to be
overly-flexible in the presence of multiple bugs.

Logistic regression and its variants uses a linearly weighted
combination of the predicates to classify a trial run as crashed or
successful.  Regularized logistic regression incorporates a penalty
that forces the regression to set most coefficients to zero, thereby
selecting only the most important predicates.  However, when the data
includes crashes caused by multiple different bugs, arbitrary linear
combinations are not always desirable.  If a predicate is a
common precondition for two different bugs, its coefficient
can be greater than the coefficients of the actual causes of the bugs.
In general, when the set of failed runs in
the training set includes crashes due to different causes, the
training process will give higher weights to sites shared by the
program paths of all bugs.\footnote{Often times, these sites may also be
shared by the paths of successful runs.  But their overall positive
effect can be offset by giving large negative weights to predicates
that are only present in successful runs (e.g. sites in unreached
portions of the code due to an early crash of the program).}

Another problem is caused by correlated predicates.
Due to the wide coverage of our instrumentation schemes, there can be
many correlated indicators of the same bug.  For example, in an
array-overrun bug, the culprit loop index variable gets abnormally
large, which manifests itself when compared to many other small
scalars in the program.  Even though technically only one of these
predicates is what we take to be the ``smoking gun'' for the bug, any
of them can be used to predict the crash.  Hence our classifier may
(rightfully) give high weights to any of the correlated features.  In
the presence of sampling, the predicates with higher coverage has the
advantage.  Alternatively, the classifier may give smaller
weights to a large number of these correlated predicates, and reserve
the larger weights for something else.  This doesn't affect
classification performance, but causes the ranking of
some of the good predicates to drop down.

For all of the above reasons, regularized logistic regression is not
outrightly appropriate for dealing with multiple bugs.  While logistic
regression attempts to combine predicates, note that the algorithm we
propose in this paper assumes that a bug is caused by a single
predicate---though more sophisticated bugs exist, the vast majority of
common bugs are simple and ``univariate.''  Looking at it this way,
the multiple bug problem diminishes, because every crashed run
ultimately crashes due to only one bug.  Hence each crash can be
accounted for by one predicate.  The predicates are then ranked by a
score depending on the number of crashes in which it is observed.  In
essence, we circumvent the multiple bug problem by letting the
``smoking guns'' cluster the crashes, not the other way around.

%% LocalWords:  pre bc downsampled
