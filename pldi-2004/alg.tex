This section presents an efficient algorithm for
isolating bugs in programs where multiple bugs are present
simultaneously.  As discussed in \Autoref{sec:background}, the
input to this algorithm is counts of the number of times pre-specified
predicates at each program point are observed to be true during program
execution.
%Because our system has no \textit{a priori} knowledge of
%what bugs may be in the program, or even any model of what the program
%does, our strategy is to make the set of predicates large in the
%expectation that if the predicate set covers enough facets of the
%program, every bug will be correlated with some predicate in the set.

Our instrumentation strategies generate very large sets
of predicates; in a typical application tens of thousands of distinct
predicates are randomly sampled during program execution.  Because the
number of distinct bugs in a program is (hopefully!) orders of
magnitude smaller than the number of instrumented predicates, the
algorithmic problem is at least as much about discarding irrelevant
predicates as it is about identifying relevant predicates.  This
observation is reflected in our algorithm, which consists of two phases:
\begin{enumerate}
\item Eliminate predicates that are not predictive of program failure.

\item Rank the predicates that remain in importance.  
\end{enumerate}

We leave ``importance'' undefined for the moment; we will return to it below.
Consider the following C code fragment, which we use to motivate and illustrate
our technique:
\begin{quote}
\begin{verbatim}
f = ...;          (a)
if (f == NULL) {  (b)
        x = 0;    (c)
        *f;       (d)
}
\end{verbatim}
\end{quote}
Consider the predicate {\tt f == NULL} at line {\tt (b)}, which would
be captured by branches instrumentation.  Clearly
this predicate is highly correlated with failure; in fact, whenever it
is true this program inevitably crashes.\footnote{We also note that this bug could 
be detected by a simple static analysis; this example is meant to be concise rather than 
a significant application of our techniques.}   An important observation,
however, is that even a ``smoking gun'' such as {\tt f == NULL} at
line {\tt (b)} cannot be a perfect predictor of failure when there are
multiple bugs in the program---since there are other bugs, the program can fail
even if the predicate is false.  There is no reason to believe that
a predicate that is a good predictor for one bug should be a good predictor 
for any other bug.

The bug in the code fragment above is \termdef{deterministic} with
respect to {\tt f == NULL}: if {\tt f == NULL} is true at line {\tt
(b)}, the program is guaranteed to eventually fail.  In many cases it
is simply impossible to observe the exact conditions that cause
failure; for example, buffer overrun bugs in a C program may or may
not cause the program to crash depending on runtime system decisions
about how data is laid out in memory.  Such bugs are
\termdef{non-deterministic} with respect to every predicate that we instrument:
even for the best predictor $P$, it is possible that $P$ is true and
still the program terminates normally.  In the example above, if we insert before line
{\tt (d)} a valid pointer  assignment to {\tt f} controlled by a conditional that is true
at least some of the time (say via a call to read input):
\begin{quote}
\begin{verbatim}
if (read()) f = ... some valid pointer ...;
*f;
\end{verbatim}
\end{quote}
then the bug becomes non-deterministic.

To summarize, even for a predicate that is truly the cause of a bug, we can neither assume that
when the predicate is true that
the program fails nor that when the predicate is false that
the program succeeds. But we can express the probability that a predicate
being true implies failure.  Let $\fail$ be an atomic predicate that is
true for failing runs and false for successful runs.  We want to compute:
\[ \crash(P) \equiv \prob(P \Rightarrow \fail) \]
for every predicate $P$ over the set of all runs.  Let $S(P)$ be the number
of successful runs in which $P$ is observed to be true at least once, and let $F(P)$ be the number of
failing runs in which $P$ is observed to be true at least once.  Then we have
\[ \crash(P) = \frac{F(P)}{S(P) + F(P)} \]

Notice that $\crash(P)$ is not affected by the set of runs in which
$P$ is observed to be false.  Thus, if $P$ is the cause of a bug, the
causes of other independent bugs do not affect $\crash(P)$.
Also note that runs in which $P$ is not observed at all (either because
the line of code on which $P$ is checked is not reached, or the line is reached
but $P$ is not sampled) have no effect on $\crash(P)$.
Finally, the definition of $\crash(P)$
generalizes the idea of deterministic and non-deterministic bugs.  A
bug is deterministic for $P$ if $\crash(P) = 1.0$ or, equivalently,
$P$ is never observed to be true in a successful run ($S(P) =
0$) and $P$ is observed to be true in at least one failing run ($F(P) > 0$).
If $\crash(P) < 1.0$ then the bug is non-deterministic, with
lower scores showing weaker correlation between the predicate and
program failure.

As we shall show, $\crash(P)$ is a useful measure, but it is not good
enough for step (1) of our algorithm. To see this, consider again the
code fragment given above (in its original form, not with the
modification to make the bug non-deterministic).  At line {\tt (b)} we
have $\crash(\mbox{\tt f == NULL}) = 1.0$, so this predicate is a good
candidate for the cause of the bug.
But on line {\tt (c)} we have the surprising fact that $\crash(\mbox{\tt x == 0}) = 1.0$ as well.
To understand why, observe that the scalar-pairs instrumentation
predicate \texttt{x == 0} is always true at line {\tt (c)} and, in
addition,
only failing runs reach this line.
Thus $S(\mbox{\tt x == 0}) = 0$, and, so long as there is at least one run that
reaches line {\tt (c)} at all, $\crash(\mbox{\tt x == 0})$ at line {\tt (c)} is 1.0.

As the predicate {\tt x == 0} at line {\tt (c)} of the example
shows, just because a predicate has a high $\crash(\ldots)$ score does not
mean it is the cause of a bug.  In the case of {\tt x == 0}, the
decision that eventually causes the crash is made earlier, and the
high $\crash(\ldots)$ score of {\tt x == 0} merely reflects the fact that this
predicate is checked on a path where the program is already doomed.

A way to address this difficulty is to score a predicate not by the chance
that it implies failure, but by how much difference it makes that the predicate
is observed to be true versus simply reaching the line where the predicate is checked.
That is, on line {\tt (c)}, the probability of crashing is already 1.0 regardless
of the value of the predicate {\tt x == 0}, and thus the fact that {\tt x == 0} is
true does not increase the probability of failure at all; this coincides with
the intuition that this predicate is irrelevant to the bug.

This leads us to the following definition:
\[ \context(P) \equiv \prob((P \lor \lnot P) \Rightarrow \fail) \]
Now, $P \lor \lnot P$ is not the set of all runs, because we are not working in a two-valued logic.
In any given run, neither of $P$ or $\lnot P$ may be observed (because the site where this predicate is
sampled is not reached), or one may be observed, or both may be observed (because the statement is executed
multiple times and $P$ is sometimes true and sometimes false).  Thus, $\context(P)$ is the probability that
in the set of runs where the value of $P$ is observed at all, the program fails. We can compute $\context(P)$ as follows:
\[ \context(P) = \frac{F(P \lor \lnot P)}{S(P \lor \lnot P) + F(P \lor \lnot P)} \]

The interesting quantity, then, is
\begin{equation*}
 \increase(P) \equiv \crash(P) - \context(P) \label{eqn:1}
\end{equation*}
%%
which can be read as: How much does $P$ being true increase the probability of failure
over simply reaching the line where $P$ is sampled?  For example, for the predicate {\tt x == 0} on line {\tt (c)},
we have
\[\crash(\mbox{\tt x == 0}) = \context(\mbox{\tt x == 0}) = 1.0 \]
and so $\increase(\mbox{\tt x == 0}) = 0$.
We can now state our algorithm:
\begin{enumerate}
\item Retain only predicates $P$ where $\increase(P) > 0$ with high confidence.

\item Sort the remaining predicates (see below).
\end{enumerate}

A few comments on this algorithm are in order.  First, pruning
predicates using $\increase(P) \leq 0$ has many desirable
properties.  It is easy to prove that large classes of irrelevant
predicates always have scores $\leq 0$.  For example, any predicate
that is not reached, that is a program invariant, or that is obviously
control-dependent on a true cause is eliminated by this test.  It is
also worth pointing out that this algorithm tends to localize bugs at
a point where the condition that causes the bug becomes true, rather than at
the crash site.  For example, in the code fragment given above, the bug is
attributed to the success of the conditional branch test {\tt f ==
NULL} on line {\tt (b)} rather than the pointer dereference on line
{\tt (d)}.  Thus, the cause of the bug discovered by the algorithm
points directly to the conditions under which the crash occurs, rather than
the line on which it occurs (which is usually available anyway in the
stack trace). \Autoref{sec:experiments:results} gives several examples
of this phenomenon while hunting for real bugs.

Because some $\increase()$ scores may be based on few observations of a predicate, it is important
to attach condfidence intervals to the scores.  Since $\increase()$ is a statistic, computing
its confidence interval is a well-understood problem; in our experiments we retain a predicate $P$
only if $\increase(P) > 0$ with 97.5\% confidence.

There are several ways to sort the surviving predicates, and each is useful.
Most often we sort by the lower bound of the confidence interval of the predicates' $\increase()$ scores.
This criteria has the effect of listing the predicates with high $\increase()$ scores and high
confidence first; these are the conditions in the program that contribute the most to failure.
Predicates with high $\increase()$ scores but wide confidence intervals are listed
later.  
There are at least two other sort orders we have found useful.  Examining 
predicates with the highest $\crash$ scores shows the prorgram points and conditions under which failure
becomes inevitable, or nearly inevitable.  Sorting by $F(P)$ (the number of failed runs in which the predicate
is true) gives a sense of how important the bug represented by the predicate is relative to the bugs represented
by other predicates. 

Thus, while the first step of our algorithm is off-line, the sorting step is on-line, allowing the user to change
the sort order as desired.  This division works well; the first step of the algorithm eliminates so many predicates
(usually well in excess of 98\%) that the second step can easily be performed at interactive speeds.

\subsection{Statistical Interpretation}

In this section we show that our test $\increase(P) > 0$ is a form of
statistical hypothesis test.  Consider the two classes of trial runs
of the program: failed runs $F$ and successful runs $S$.  For each
class, we can treat the predicate $P$ as a Bernoulli random variable
with heads probabilities $\pi_f(P)$ and $\pi_s(P)$, respectively, for the
two classes.  The heads
probability is the probability that the predicate is observed to be
true.  If a predicate causes a set of crashes, then $\pi_f$ should be
much bigger than $\pi_s$.  We can formulate two statistical hypotheses:
the null hypothesis $\H_0:
\pi_f \leq \pi_s$, vs.\ the alternate hypothesis $\H_1: \pi_f > \pi_s$.  Since
$\pi_f$ and $\pi_s$ are not known, we must estimate them from our
data.
\begin{align*}
  \hat \pi_f(P) &= \frac{F(P)}{F(P \lor \lnot P)} &
  \hat \pi_s(P) &= \frac{S(P)}{S(P \lor \lnot P)}
\end{align*}

Although these proportion estimates of $\pi_f$ and $\pi_s$ approach the
actual heads probabilities as we increase the number of trial runs, they
still differ due to sampling.  With a certain probability, using these
estimates instead of the actual values result in the wrong
answer.  A \textit{likelihood ratio test} takes this uncertainty into
account, and makes use of the statistic $ Z = \frac{(\hat \pi_f - \hat
  \pi_s)}{V_{f,s}}$, where $V_{f,s}$ is a sample variance term (see
e.g., ~\cite{Lehmann:1986:hyptest}).  When
the data size is large, $Z$ can be approximated as a standard Gaussian
random variable.  Performed independently for each predicate $P$, the
test decides whether or not $\pi_f(P) \leq \pi_s(P)$ with a guaranteed
false-positive probability (i.e.,\ choosing $\H_1$ when $\H_0$ is true).
A necessary (but not sufficient) condition for choosing $\H_1$ is that
$\hat \pi_f(P) > \hat \pi_s(P)$.  This turns out to be
equivalent to the condition that $\increase(P) > 0$.  To see this,
let $a = F(P)$, $b = S(P)$, $c = F(P\lor\lnot P)$, and $d = S(P\lor\lnot P)$.
Then
\begin{gather*}
  \increase(P) > 0 \iff \crash(P) > \context(P) \\
  \iff \frac{a}{a+b} > \frac{c}{c+d}
  \iff a (c+d) > (a+b) c \\
  \iff ad > bc \iff \frac{a}{c} > \frac{b}{d}
  \iff \hat \pi_f > \hat \pi_s
\end{gather*}

Hence the $\increase(P) > 0$ criterion is not only well motivated
from the program analysis point of view, but can also be seen as a
version of a likelihood ratio test.

\subsection{Comparison with Logistic Regression}
\label{sec-comparison}

In earlier work \cite{PLDI`03*141,Zheng:2003:SDSP}
we made use of $\ell_1$-regularized logistic regression and similar
methods to select and rank the predicates in the order of their
failure-prediction strength.  Independently others have used
logistic regression with good results to cluster program failures (without
identifying causes) related to the same bug \cite{ICSE`03*465}.  However, we have come
to believe the logistic regression has limits
in these sorts of applications. 

Logistic regression and its variants use a linearly weighted
combination of the predicates to classify a trial run as successful or
failed.  Regularized logistic regression incorporates a penalty
that forces the regression to set most coefficients to zero, thereby
selecting only the most important predicates.  The output is a set of
coefficients for predicates that gives the best overall prediction: i.e., if
certain predicates are true the program is likely to fail.

Reasoning from first principles, there are two potential problems with
this approach in our setting.  First, it is not clear what the weights
on the predicates mean, or that there is always an assignment of
weights that optimally captures the behavior of a program with
multiple bugs.  Secondly, it is not clear how to choose the penalty
factor.  We have found the second issue is minor in practice.  For the
first issue, one might guess that the difficulty, if it exists, shows
up as the number and complexity of the program's bugs
increases.  This will tend to increase the number of predicates that
are at least somewhat predictive of failure and, more significantly,
dramatically increase the number of sets of predicates that could
explain all failures, thereby making it more difficult for logistic
regression to pick a good set of predicates and coefficients from a very large
space.  

In fact, we observe that logistic regression performs worse
in more complex situations. For example, if a predicate is a
common precondition for two different bugs, its coefficient
can be greater than the coefficients of the actual causes of the bugs.
In general, when the set of failed runs in
the training set includes crashes due to different causes, the
training process will give higher weights to sites shared by the
program paths of all bugs.\footnote{Often times, these sites may also be
shared by the paths of successful runs.  But their overall positive
effect can be offset by giving large negative weights to predicates
that are only present in successful runs (e.g.,\ sites in unreached
portions of the code due to an early crash of the program).}

Another problem is caused by the wide coverage of our instrumentation
schemes, which tends to result in many correlated indicators of the
same bug.  For example, in an array-overrun bug, the culprit loop
index variable gets abnormally large, which manifests itself when
compared to many other small scalars in the program.  Logistic
regression may (rightfully) give high weights to any of these
correlated features and drop others from its model.  In the presence
of sampling, the predicates with higher coverage have the advantage.
Alternatively, the classifier may give smaller weights to a large
number of these correlated predicates, and reserve the larger weights
for something else. 
In either case, the ranking of some useful predicates can be quite low.

We cannot conclude from our experience that logistic regression cannot
be made to scale to the analysis of complex software failures, but we
note that our hypothesis about scaling behavior is at least
consistent with earlier, positive results.  Our own previous study
focused on programs with a single bug; thus all predicates with any
predictive power were predicting the same failure mode, making it
easier for logistic regression to select predicates and weights to
represent all failures.  In the previous work on failure clustering
\cite{ICSE`03*465}, the number of features (predicates) is equal to
the number of procedures in the program.  Using fewer features 
improves the performance of logistic regression, as it has fewer choices to
make; in this case the number of features is at least two orders of
magnitude less than in our applications.

For the reasons discussed above, regularized logistic regression has
limitations for dealing with multiple bugs in our applications.  While logistic
regression attempts to combine predicates, note that the algorithm we
propose here focuses on how well each predicate $P$ explains the set of failed
runs in which $P$ is observed.
In essence, we circumvent the multiple bug problem by letting the
predicates cluster the failed runs, not the other way around. 

%% LocalWords:  pre bc downsampled
