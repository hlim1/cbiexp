This section presents our algorithm for automatically isolating
multiple bugs.  As discussed in \autoref{sec:background}, the input is
a set of feedback reports from individual program runs $R$, where
$\report{P} = 1$ if predicate $P$ is observed to be true during the
execution of $R$.

The idea behind the algorithm is to simulate the iterative manner in which  human programmers
typically find and fix bugs:
\begin{enumerate}

\item Identify the most important bug $\bug$.

\item Fix $\bug$, and repeat.

\end{enumerate}

For our purposes, identifying a bug $\bug$ means selecting a
predicate $P$ closely correlated with its bug profile $\bugprofile$.  The difficulty is that we
know the set of runs that succeed and fail, but we do not know which
set of failing runs corresponds to $\bug$, or even how many bugs there
are.  In other words, we do not know the sizes or membership of the set
of bug profiles $\{\bugprofile_i\}$.
Thus, in the first step we must infer which predicates are most
likely to correspond to individual bugs and rank those predicates in
importance.

For the second step, while we cannot literally fix the bug
corresponding to the chosen predictor $P$, we can simulate what
happens if the bug does not occur.  We discard any run $R$ such that
$\report{P} = 1$ and recursively apply the entire algorithm to the remaining runs.  Discarding all the runs where
$\report{P} = 1$ reduces the importance of other predictors of
$\bug$, allowing predicates that predict different bugs (i.e.,
corresponding to different sets of failing runs) to rise to the top in
subsequent iterations.

\subsection{Increase Scores}
\label{sec:increase}

We now discuss the first step: how to find the cause of the most important bug.
We break this step into two sub-steps.  First, we eliminate predicates that have no
predictive power at all; this typically reduces the number of predicates we need
to consider by two orders of magnitude (e.g., from hundreds of thousands to thousands).
Next, we rank the surviving predicates by importance (see \autoref{sec:ranking}).

Consider the following C code fragment:
\begin{quote}
\begin{verbatim}
f = ...;          (a)
if (f == NULL) {  (b)
    x = 0;        (c)
    *f;           (d)
}
\end{verbatim}
\end{quote}
Consider the predicate \texttt{f == NULL} at line \texttt{(b)}, which would
be captured by branches instrumentation.  Clearly
this predicate is highly correlated with failure; in fact, whenever it
is true this program inevitably crashes.\footnote{We also note that this bug could
be detected by a simple static analysis; this example is meant to be concise rather than
a significant application of our techniques.}   An important observation,
however, is that there is no one perfect predictor of failure in a
program with multiple bugs.  Even a ``smoking gun'' such as \texttt{f ==
  NULL} at line \texttt{(b)} has little or no predictive power for
failures due to unrelated bugs in the same program.

The bug in the code fragment above is \termdef{deterministic} with
respect to \texttt{f == NULL}: if \texttt{f == NULL} is true at line
\texttt{(b)}, the program fails.  In many cases it is impossible to observe
the exact conditions causing failure; for example, buffer overrun bugs
in a C program may or may not cause the program to crash depending on
runtime system decisions about how data is laid out in memory.  Such
bugs are \termdef{non-deterministic} with respect to every observed predicate;
even for the best predictor $P$, it is possible
that $P$ is true and still the program terminates normally.  In the
example above, if we insert before line \texttt{(d)} a valid pointer
assignment to \texttt{f} controlled by a conditional that is true at
least occasionally (say via a call to read input)
\begin{quote}
\begin{verbatim}
if (...) f = ... some valid pointer ...;
*f;
\end{verbatim}
\end{quote}
the bug becomes non-deterministic with respect to \texttt{f == NULL}.

To summarize, even for a predicate $P$ that is truly the cause of a bug, we can neither assume that
when $P$ is true that
the program fails nor that when $P$ is never observed to be true  that
the program succeeds.
But we can express the probability that $P$
being true implies failure.  Let $\fail$ be an atomic predicate that is
true for failing runs and false for successful runs.  Let $\prob(A | B)$ denote
the conditional probability function of the event $A$ given event $B$.
We want to compute:
\[ \crash(P) \equiv \prob(\fail | \text{$P$ observed to be true}) \]
for every instrumented predicate $P$ over the set of all runs.  Let $S(P)$ be the number
of successful runs in which $P$ is observed to be true, and let $F(P)$ be the number of
failing runs in which $P$ is observed to be true.
We estimate $\crash(P)$ as:
\[ \crash(P) = \frac{F(P)}{S(P) + F(P)} \]

Notice that $\crash(P)$ is unaffected by the set of runs in which
$P$ is not observed to be true.  Thus, if $P$ is the cause of a bug, the
causes of other independent bugs do not affect $\crash(P)$.
Also note that runs in which $P$ is not observed at all (either because
the line of code on which $P$ is checked is not reached, or the line is reached
but $P$ is not sampled) have no effect on $\crash(P)$.
The definition of $\crash(P)$
generalizes the idea of deterministic and non-deterministic bugs.  A
bug is deterministic for $P$ if $\crash(P) = 1.0$, or equivalently,
$P$ is never observed to be true in a successful run ($S(P) =
0$) and $P$ is observed to be true in at least one failing run ($F(P) > 0$).
If $\crash(P) < 1.0$ then the bug is non-deterministic with respect to $P$.
Lower scores show weaker correlation between the predicate and
program failure.

Now $\crash(P)$ is a useful measure, but it is not good
enough for the first step of our algorithm. To see this, consider again the
code fragment given above in its original, deterministic form.  At line \texttt{(b)} we
have $\crash(\texttt{f == NULL}) = 1.0$, so this predicate is a good
candidate for the cause of the bug.
But on line \texttt{(c)} we have the unpleasant fact that $\crash(\texttt{x == 0}) = 1.0$ as well.
To understand why, observe that the
predicate \texttt{x == 0} is always true at line \texttt{(c)} and, in
addition,
only failing runs reach this line.
Thus $S(\texttt{x == 0}) = 0$, and, so long as there is at least one run that
reaches line \texttt{(c)} at all, $\crash(\texttt{x == 0})$ at line \texttt{(c)} is 1.0.

As this example
shows, just because $\crash(P)$ is high does not
mean $P$ is the cause of a bug.  In the case of \texttt{x == 0}, the
decision that eventually causes the crash is made earlier, and the
high $\crash(\texttt{x == 0})$ score merely reflects the fact that this
predicate is checked on a path where the program is already doomed.

A way to address this difficulty is to score a predicate not by the
chance that it implies failure, but by how much difference it makes
that the predicate is observed to be true versus simply reaching the
line where the predicate is checked.  That is, on line \texttt{(c)},
the probability of crashing is already 1.0 regardless of the value of
the predicate \texttt{x == 0}, and thus the fact that \texttt{x == 0}
is true does not increase the probability of failure at all.  This
fact coincides with our intuition that this predicate is irrelevant to
the bug.

Recall that we write ``$P$ observed'' when $P$ has been reached
and sampled at least once, without regard to whether $P$ was actually
true or false.
This leads us to the following definition:
\[
\context(P) \equiv \prob(\fail | \text{$P$ observed})
\]
Now, it is not the case that $P$ is observed in every run, because the
site where this predicate occurs may not be reached, or may be reached
but not sampled.
%% or is reached but not sampled.
%% Now, it is not the case that $P \lor \lnot P = 1$ in every run, because we are not working in a two-valued logic:
%% In a given run, it is possible that neither $P$ nor $\lnot P$ is observed because the site where this predicate occurs is not reached,
%% or is reached but not sampled.
%In any given run, there are three possibilities: (a) neither $P$ nor $\lnot P$
%is observed (because the site where this predicate occurs is not reached, or is reached but not sampled),
%(b) one of $P$ or $\lnot P$ is observed, or (c) both are observed (because the statement is executed
%multiple times and $P$ is sometimes true and sometimes false).
Thus, $\context(P)$ is the probability that
in the subset of runs where the site containing predicate $P$ is reached and sampled, the program fails.
We can estimate $\context(P)$ as follows:
\[ \context(P) = \frac{F(\text{$P$ observed})}{S(\text{$P$ observed}) +
  F(\text{$P$ observed})} \]

The interesting quantity, then, is
\begin{equation*}
 \increase(P) \equiv \crash(P) - \context(P) \label{eqn:1}
\end{equation*}
%%
which can be read as: How much does $P$ being true increase the probability of failure
over simply reaching the line where $P$ is sampled?  For example, for the predicate \texttt{x == 0} on line \texttt{(c)},
we have
\[\crash(\texttt{x == 0}) = \context(\texttt{x == 0}) = 1.0 \]
and so $\increase(\texttt{x == 0}) = 0$.

A predicate $P$ with $\increase(P) \leq 0$ has no predictive power.  Being true does not increase the
probability of failure, and we can safely discard all such predicates.
But because some $\increase(P)$ scores may be based on few observations of $P$, it is important
to attach confidence intervals to the scores.  Since $\increase(P)$ is a statistic, computing
a confidence interval for the underlying parameter is a well-understood problem. In our experiments we retain a predicate $P$ only if 
the 95\% confidence interval based on  $\increase(P)$ lies
strictly above zero; this removes predicates from consideration 
that have high increase scores but very low confidence because of 
few observations.

Pruning predicates based on $\increase(P)$ has several desirable
properties.  It is easy to prove that large classes of irrelevant
predicates always have scores $\leq 0$.  For example, any predicate
that is unreachable, that is a program invariant, or that is obviously
control-dependent on a true cause is eliminated by this test.  It is
also worth pointing out that this test tends to localize bugs at
a point where the condition that causes the bug first becomes true, rather than at
the crash site.  For example, in the code fragment given above, the bug is
attributed to the success of the conditional branch test \texttt{f ==
NULL} on line \texttt{(b)} rather than the pointer dereference on line
\texttt{(d)}.  Thus, the cause of the bug discovered by the algorithm
points directly to the conditions under which the crash occurs, rather than
the line on which it occurs (which is usually available anyway in the
stack trace).

\subsection{Statistical Interpretation}
\label{sec:statisticalinterpretation}

We have explained the test $\increase(P) > 0$ using programming terminology,
but it also has a natural statistical interpretation as a simplified likelihood ratio hypothesis
test.  Consider the two classes of trial runs
of the program: failed runs $F$ and successful runs $S$.  For each
class, we can treat the predicate $P$ as a Bernoulli random variable
with heads probabilities $\pi_f(P)$ and $\pi_s(P)$, respectively, for the
two classes.  The heads
probability is the probability that the predicate is observed to be
true.  If a predicate causes a set of crashes, then $\pi_f$ should be
much bigger than $\pi_s$.  We can formulate two statistical hypotheses:
the null hypothesis $\H_0:
\pi_f \leq \pi_s$, versus the alternate hypothesis $\H_1: \pi_f > \pi_s$.  Since
$\pi_f$ and $\pi_s$ are not known, we must estimate them:
\begin{align*}
  \hat \pi_f(P) &= \frac{F(P)}{F(\text{$P$ observed})} &
  \hat \pi_s(P) &= \frac{S(P)}{S(\text{$P$  observed})}
\end{align*}

Although these proportion estimates of $\pi_f$ and $\pi_s$ approach the
actual heads probabilities as we increase the number of trial runs, they
still differ due to sampling.  With a certain probability, using these
estimates instead of the actual values results in the wrong
answer.  A \textit{likelihood ratio test} takes this uncertainty into
account, and makes use of the statistic $ Z = \frac{(\hat \pi_f - \hat
  \pi_s)}{V_{f,s}}$, where $V_{f,s}$ is a sample variance term (see,
e.g., \cite{Lehmann:1986:hyptest}).  When
the data size is large, $Z$ can be approximated as a standard Gaussian
random variable.  Performed independently for each predicate $P$, the
test decides whether or not $\pi_f(P) \leq \pi_s(P)$ with a guaranteed
false-positive probability (i.e.,\ choosing $\H_1$ when $\H_0$ is true).
A necessary (but not sufficient) condition for choosing $\H_1$ is that
$\hat \pi_f(P) > \hat \pi_s(P)$.  However, this is
equivalent to the condition that $\increase(P) > 0$.  To see why,
let $a = F(P)$, $b = S(P)$, $c = F(\text{$P$ observed})$, and $d =
S(\text{$P$ observed})$.
Then
\begin{gather*}
  \increase(P) > 0 \iff \crash(P) > \context(P) \\
  \iff \frac{a}{a+b} > \frac{c}{c+d}
  \iff a (c+d) > (a+b) c \\
  \iff ad > bc \iff \frac{a}{c} > \frac{b}{d}
  \iff \hat \pi_f(P) > \hat \pi_s(P)
\end{gather*}

\subsection{Balancing Specificity and Sensitivity}
\label{sec:ranking}

\input{moss-view/stats-breakout}

\newlength{\textsegwidth}
\setlength{\textsegwidth}{2ex}
\newcommand{\textseg}[1]{\parbox{\textsegwidth}{\segment{#1}{\textsegwidth}}}

We now turn to the question of ranking those predicates that survive
pruning.  \autoref{tab:sorts} shows the top predicates under different
ranking schemes (explained below) for one of our experiments.  Due to
space limitations we omit additional per-predicate information, such
as source file and line number, which is available in the interactive
version of our analysis tools.

We use a concise \termdef{bug thermometer} to visualize the
information for each predicate.  The length of the thermometer is
logarithmic in the number of runs in which the predicate was observed,
so small increases in thermometer size indicate many more runs.  Each
thermometer has a sequence of bands.  The black band on the left shows
$\context(P)$ as a fraction of the entire thermometer length.  The
dark gray band (\textseg{red}) shows the lower bound of $\increase(P)$
with 95\% confidence, also proportional to the entire thermometer
length.  The light gray band (\textseg{pink}) shows the size of that
confidence interval.\footnote{If reading this paper in color, the dark
gray band is red, and the light gray band is pink.}  It is very small
in most thermometers, indicating a tight interval.  The white space at
the right end of the thermometer shows $S(P)$, the number of
successful runs in which the predicate was observed to be true.  The
tables show the thermometer as well as the numbers for each of the
quantities that make up the thermometer.

The most important bug is the one that causes the greatest number of
failed runs.  This observation suggests:
%%
\[ \importance(P) = F(P) \]
%%
\autoref{tab:sorts-failure} shows the top predicates ranked by
decreasing $F(P)$ after predicates where $\increase(P) \leq 0$ are
discarded.  The predicates in \autoref{tab:sorts-failure} are, as
expected, involved in many failing runs.  However, the large white
band in each thermometer reveals that these predicates are also highly
non-deterministic: they are also true in many successful runs and are
weakly correlated with bugs.  Furthermore, the very narrow dark gray
bands (\textseg{red}) in most thermometers indicate that most
$\increase$ scores are very small.

Our experience with other ranking strategies that emphasize the number
of failed runs is similar.  They select predicates involved in many
failing, but also many successful, runs.  The best of these predicates
(the ones with high $\increase$ scores) are \termdef{super-bug
  predictors}: predictors that include failures from more than one
bug.  Super-bug predictors account for a
very large number of failures by combining the failures of multiple
bugs, but are also highly non-deterministic (because they are not 
specific to any single cause of failure) despite reasonably high
$\increase$ scores.

Another possibility is:
%%
\[ \importance(P) = \increase(P) \]
%%
\autoref{tab:sorts-increase} shows the top predicates ranked by
decreasing $\increase$ score.  Thermometers here are almost entirely
dark gray (\textseg{red}), indicating $\increase$ scores that are very
close to 1.0.  These predicates do a much better job of predicting
failure.  In fact, the program always fails when any of these
predicates is true.  However, observe that the number of failing runs
(column $F$) is very small.  These predicates are \termdef{sub-bug
  predictors}: predictors for a subset of the failures caused by a
bug.  Unlike super-bug predictors, which are not useful in our
experience, sub-bug predictors that account for a significant fraction
of the failures for a bug often provide valuable clues.  However still
they represent special cases and may not suggest other, more
fundamental, causes of the bug.

Tables~\ref{tab:sorts-failure} and \ref{tab:sorts-increase} illustrate
the difficulty of defining ``importance.''  We are looking for
predicates with high \termdef{sensitivity}, meaning predicates that
account for many failed runs.  But we also want high
\emph{specificity}, meaning predicates that do not mis-predict failure
in many successful runs.  In information retrieval, the corresponding
terms are \termdef{recall} and \termdef{precision}.  A standard way to combine sensitivity
and specificity is to compute their harmonic mean; this measure
prefers high scores in both dimensions.  In our case, $\increase(P)$
measures specificity.  For sensitivity, we have found it useful to
consider a transformation $\phi$ of the raw counts, and to form the
normalized ratio $\phi(F(P)) / \phi(\numfail)$, where $\numfail$ is
the total number of failed runs.  In our work thus far $\phi$ has been
a logarithmic transformation, which moderates the impact of very large
numbers of failures.  Thus our overall metric is the following:
%%
\[
\importance(P) =
\frac{2}{
  \frac{1}{\increase(P)}
  +
  \frac{1}{log(F(P)) / log(\numfail)}}
\]

It is possible for this formula to be undefined (due to a division by 0),
in which case we define the \importance\ to be 0.
\autoref{tab:sorts-harmonic}(c) gives results using this metric.
Both individual $F(P)$ counts and individual $\increase(P)$ scores are smaller than in
\autoref{tab:sorts-failure} and \autoref{tab:sorts-increase}, but the harmonic mean
has effectively balanced both of these important factors.  All of the
predicates on this list indeed have both high specificity and
sensitivity.  Each of these predictors accurately describes a large
number of failures.

\subsection{Redundancy Elimination}
\label{sec:elimination}

The remaining problem with the results in \autoref{tab:sorts-harmonic}
is that there is substantial redundancy; it is easy to see that
several of these predicates are related.  This redundancy hides other,
distinct bugs that either have fewer failed runs or more
non-deterministic predictors further down the list.  As discussed
previously, beginning with the set of all runs and predicates, we use
a simple iterative algorithm to eliminate redundant predicates:
\begin{enumerate}

\item Rank predicates by $\importance$.

\item Remove the top-ranked predicate $P$ and discard all runs $R$
  (feedback reports) where $\report{P} = 1$.

\item Repeat these steps until the set of runs is empty or the set of predicates is empty.
\end{enumerate}

We can now state an easy-to-prove but important property of this algorithm.
\begin{lemma}
\label{lem1}
Let $P_1,\ldots,P_n$ be a set of instrumented predicates, $\bug_1,\ldots,\bug_m$
a set of bugs, and $\bugprofile_1,\ldots, \bugprofile_2$ the corresponding
bug profiles.  Let
\[ {\cal Z} = \bigcup_{1 \leq i \leq n} \{ R | \report{P_i} = 1 \} . \]
If for all $1 \leq j \leq m$ we have $\bugprofile_j \cap {\cal Z} \neq \emptyset$, then
the algorithm chooses at least one predicate from the list $P_1,\ldots,P_n$ that predicts
at least one failure due to $\bug_j$.
\end{lemma}

Thus, the elimination algorithm chooses at least one predicate
predictive of each bug represented by the input set of predicates.
We are, in effect, covering the set of bugs with a ranked subset of predicates.
The other property we might like, that the algorithm chooses exactly
one predicate to represent each bug, does not hold; we shall see in
\autoref{sec:experiments} that the algorithm sometimes selects a
strong sub-bug predictor as well as a more natural predictor.  (As a
technical aside, note that \autoref{lem1} does not guarantee that every
selected predicate has a positive \increase\ score at the time it is
selected.  Even if predicates with non-positive \increase\ scores are
discarded before running the elimination algorithm, new ones can arise
during the elimination algorithm.  However, the
\increase\ score of any predicate that covers at least one failing run will
at least be defined.  See \autoref{sec:extensions} for related discussion.)

Beyond always representing each bug, the algorithm works well for two
other reasons.  First, two predicates are redundant if they predict
the same (or nearly the same) set of failing runs.  Thus, simply
removing the set of runs in which a predicate is true automatically
dramatically reduces the importance of any related predicates in the
correct proportions. Second, because elimination is iterative, it is
only necessary that $\importance$ selects a good predictor at each
step, and not necessarily the best one; any predicate that covers a
different set of failing runs than all higher-ranked predicates is
selected eventually.

Finally, we studied an optimization in which we eliminated logically redundant
predicates within instrumentation sites prior to running the iterative algorithm.
%For instance, given three scalar-pairs predicates $x < y$, $x = y$, and
%$x \leq y$ having the same \increase\ score at an instrumentation site, we 
%eliminated both $x < y$ and $x = y$.
However, the elimination algorithm proved to be sufficiently powerful that
we obtained nearly identical experimental results with and without 
this optimization, indicating it is unnecessary. 

