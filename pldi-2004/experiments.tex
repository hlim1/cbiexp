
This section describes the results of applying the algorithm discussed
in \Autoref{sec:algorithm} to the experiment described in
\Autoref{sec:experiments:setup}.  We performed 31,996 random runs of
\moss\footnote{Which, not coincidentally, turns out to be the maximum
number of files and subdirectories permitted in a Linux directory.
The results of each run is saved in its own subdirectory.}  Of these,
123 runs were discarded because they produced no report (see \Autoref{sec:experiments:setup}),
giving us 31,873 runs to work with.  

For this experiment we used three different instrumentation strategies, which our
instrumentor automatically combined in a single executable:
\begin{itemize}
\item {\em branches}: For each if statement {\tt if (P) \ldots} we sample whether {\tt P} is true or false.
Two predicates are tracked for each {\tt if} ($\tt P$ and $\tt \neg P$).  There were 2,085 such conditional branches
in \moss, yielding 4,170 predicates.

\item {\em returns}: For each procedure we sample whether its return value $\tt r$ is positive, negative, or zero.
These three counters give rise to six predicates in the analysis: $\tt r = 0$, $\tt \neq 0$, $\tt r < 0$, $\tt r \leq 0$, $\tt r > 0$, and $\tt r \geq 0$.
There were 494 return sites in \moss, yielding 2,964 predicates.

\item {\em scalar-pairs}: At each assignment {\tt x = \ldots} and every other variable with the same type as {\tt x} that is in scope,
we sample whether $\tt x < y$, $\tt x = y$, or $\tt x > y$.  These
three counters also give rise to six predicates that are examined in
the analysis: $\tt x = y$, $\tt x \neq y$, $\tt x < y$, $\tt x \leq
y$, $\tt x > y$, and $\tt x \geq y$.  This instrumentation strategy 
also includes assignments to struct fields of the form {\tt foo.x =
\ldots}.  Furthermore, in addition to comparing the left-hand side of
an assignment with same-typed variables, the left-hand side is also compared against
same-typed manifest constants that appear in the program.  There are
32,644 such combinations of assignments and variables or constants
to compare in \moss, yielding 195,864 predicates in the analysis.
\end{itemize}

Thus, the input to our analysis is 31,873, each of which records the
status of over 200,000 predicates.\footnote{The reader may wonder
whether it is practical to actually generate a report on 200,000
predicates on a client machine and then upload it to a central server
for analysis.  The answer is definitely yes.  These reports are mostly
zeroes and so compress extremely well, resulting in uploaded files in
the range of 10-50K.}  The sampling rate for all runs in this
experiment was 1/1; i.e., we sampled every predicate every time it was
reached.  We used a separate downsampling program to generate sparser
samples from this full data; thus, we were able to use the same set of
runs to test the effect of different sampling rates on the results.

Step one of our algorithm eliminates almost all of the predicates.  At
1/100 sampling, the numbers of predicates with a positive
$\increase(\ldots)$ score are

\begin{itemize}
\item 51 branch predicates;

\item 16 returns predicates;

\item 8,672 scalar-pairs predicates.
\end{itemize}
\placeholder{We need to replace the 8,672 number with the number of distinct sites that survived step 1 in the 1/100 downsampled data.  This is the fairest number to report.}
About 99\% of all predicates in the the branch and returns
instrumentation strategies are eliminated by step (1) of our
algorithm, and the lists are short enough that almost no ranking is
needed.  About 96\% of the predicates in the scalar-pairs strategy are
eliminated, but clearly ranking is still important because of the
large number of predicates that remain.

\subsection{The Bugs}
\placeholder{Alex writes this}

\subsection{Analysis of Predicate Elimination}
\placeholder{Mayur writes this}

\subsection{Effect of Sampling on Convergence}
\placeholder{Alice writes this}





