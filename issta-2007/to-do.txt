Put name markers in brackets after items in the to-do list:

  +Foo: things Foo is best suited to work on or plans to work on
  -Foo: things Foo is definitely not able to work on
  *Foo: things Foo is working on right now

If you see a problem but either cannot fix it or don't want to work on
it now, add it to the list below so that it will not be overlooked or
forgotten.  Try to keep to-do items roughly organized by section,
except for whole-paper issues which are listed first.

As you fix outstanding items, remove them from the list and check in
this updated to-do list along with your changes.  When this list is
empty, that basically means we're done!

------------------------------------------------------------------------
--
--  Review 1
--

>> The authors present an approach for estimating the debugging 
>> effort required from the predicate. In order to demonstrate the accuracy
>> of these estimation techniques one has to conduct an experimental study
>> that records the debugging effort by programmers.

1. Add clarification/response for the above comment:

>> The authors present techniques such as pruning in order to reduce
>> the cost of monitoring. They also reduce complex predicates to combinations
>> of two simple predicates in order to limit monitoring costs. However, the
>> experiments reported in the paper do not discuss the monitoring overhead.
>> It is not clear from this paper if the monitoring overhead caused by complex
>> predicates is an acceptable overhead. It would have helped if the authors 
>> presented some data about the runtime monitoring overhead and how it is
>> effected by the presented pruning techniques, or how bad it would be
>> if one uses complex predicates that contain three or more simple predicates.

2. Clarify that we do not change the execution monitoring in any way

------------------------------------------------------------------------
--
--  Review 2
--

>> Can you think of a better term for "interesting" complex predicates.
>> Interesting is a rather anodyne term in this context.

1. Come up with a more suitable term than "interesting"
2. Make sure ALL references to "interesting" are changed.

>> The treatment of scoring predicates is somewhat glossed over. I would like to
>> see a little more explanation here, For example, you could motivate why it is
>> necessary to take logs for sensitivity and why the harmonic mean is preferred
>> to some other method of aggregating the two values.

5. Add a suitable response.  For e.g., "See [PLDI '05] for a detailed
explanation

>> In section 3.4 the claim that bounding the predicates does not affect the
>> results surely has the hidden assumption that an error is caused by a single
>> fault? If so then I think that this should be stated. Naturally errors caused
>> by the co-occurrence of several faults are unlikely, but then they are also the
>> most subtle and important of all faults. Are there any other assumptions in
>> this claim (in section 3.4)? It is a very strong claim and I don't see that the
>> proof is obvious. Have I missed something? Some words of proof sketch would be
>> helpful (unless you are sure that it is obvious in which case I've missed
>> something).

6. I completely miss the point here.  Perhaps one of you could clarify the 
question of the comment

>> I was disappointed that the references were not complete (for example 3, 10 and
>> 16, missing volume numbers, parts, and pages).

8. Fill in all the details about citations.
(Honestly, who needs page numbers?)

------------------------------------------------------------------------
--
--  Review 3
--

>> I had some trouble understanding the discussion of the pruning of complex
>> predicates in Section 3.4. I think it would be helpful to add a small 
>> example to illustrate why a given complex predicate can be pruned before 
>> run information is generated.  What confuses me here is the term "before 
>> run information is generated".  Presumably you already have some information 
>> about the effectiveness of simple predicates?  Please clarify.

(I think we do have an example)
1. explain that applying the truth tables itself is an expensive task and we
are tackling that by pruning.. not generation of reports itself

>> The discussion of the effectiveness of complex predicates for lower
>> sampling rates in Section 6 could be improved. I think it would be very 
>> useful to include counterparts to Table 8 (where sampling rate is 1 if 
>> I understand you correctly) with sampling rates of 0.1, 0.01, ...

2. Unfortunately this needs a lot of real estate.  May be we can add one more
table, for e.g. with rate 1/100.
(Fortunately, we do have the required data.. no need to go back to condor)

>> The paper could make a stronger case for the usefullness of disjunctions.
>> Figure 1(b) seems to imply that they're completely uselesss. Perhaps a 
>> small experiment of a variation on a Siemens program with multiple bugs 
>> could be used to argue in favor of disjunctions?

3. Disjunctions are less useful with multiple bugs as we don't know if we are
picking up primary predictors of 2 bugs or a single bug with disjunctive 
predictor.  This is mentioned somewhere.  Revise its text and placement if
necessary.

>> Related work by Alex Orso, Adam Porter et al. on the classification of data
>> from deployed software should be discussed.

4. Gosh!  Add that right away.

------------------------------------------------------------------------
--
--  Section 4
--

Section 4 offers some interesting ideas, though they aren't explored
or justified as fully as they could be.  I'm not convinced that
Definition 4.2 is working in the right direction.  If two predicates
are highly correlated according to this definition, doesn't that mean
they are nearly identical and therefore not especially interesting as
a pair?  I would have thought that an interesting pair predicates
would be ones with very little apparent connection in the PDG, but
which nonetheless are tightly connected in how they predict failures.
[+chen]

Choosing predicates with the smallest intersection of predecessor sets also 
relates well with the revised motivation for the metrics; the smaller 
the intersection, the easier it is for a programmer to search the 
code related to both predicates to find the connection.  By the current 
definition "highly correlated" predicate combinations are selected; 
this means a programmer has a potentially huge intersection set to
search through for the item which 1. connects the components and 
2. relates to the bug.
