% -*- TeX-master: "master" -*-

\section{Related Work}
\label{sec-related-work}
Daikon \cite{ErnstCGN2001:TSE} detects invariants in a program by observing multiple program runs.  Invariants are predicates generated using operators like sum, max, etc.\ to combine program variables and collection (e.g., array) objects.  Daikon is intended for many uses beyond bug isolation, and so it monitors a much larger set of predicates than CBI.  This makes scalable complex predicate generation more difficult.  However, Dodoo et al.\ \cite{ErnstDRAFT} have successfully extended the work to generate implications from the simpler, measured predicates.  Dodoo et al.\ alternate clustering and invariant detection to find invariant implications over a set of program runs.  The initial clustering is performed using the $k$-means algorithm \cite{jain99data}, with program runs represented as normalized vectors of scalar variable values.  Since CBI represents run information as bit-vectors this technique can be applied essentially unchanged.

Daikon's implication generation extends its vocabulary of possible invariants.  CBI's focus is detection of bug predictors, which under sparse sampling conditions can rarely be identified as invariant.  Additionally, the existence of an implication is of questionable value in this project; the implication revealed in \autoref{sec-ccrypt} is an interesting and potentially useful side-effect of our analysis, but only because it involves identified bug predictors.  The approach described in this paper is better suited to the goals and analysis techniques of CBI\@.  There are no known attempts to use Daikon under sparse sampling conditions.

DIDUCE \cite{581377} detects invariant bits of program values during an initial training phase.  During the checking phase, DIDUCE reports each invariant violation as it occurs, then relaxes the invariant to accept the new value.  Unlike Daikon and CBI, DIDUCE tightly couples data collection and evaluation.  Because of this coupling, neither our nor Daikon's offline style of predicate generation is readily combined with DIDUCE's framework.

Haran et al.\ \cite{haran05TCEDS} analyze data from deployed software to classify executions as \emph{success} or \emph{failure}.  They use tree based classifiers and association rules to model ``failure signals.''  Tree based classifiers can encode both conjunctions and disjunctions whereas association rules cannot encode disjunctions when limited to a constant size.

SOBER \cite{1081753} is a statistical debugging tool similar to CBI\@.  Where CBI considers only whether a predicate was ever observed true during an execution, SOBER estimates the likelihood of it being true at any given evaluation.  SOBER data is a probability vector, with each value representing the estimated chance of a simple predicate being true when observed.  The similarity in collected data means that similar techniques for complex predicate generation are applicable.  The three-valued logic described in \autoref{sec-tvl} could be replaced with joint-probability when generating conjunctions; De Morgan's law can be applied to generate disjunctions.  Our usability metrics can be used on the resulting data.  There are no known experiments using SOBER under sparse sampling conditions.  Complex predicate generation removes a key advantage of SOBER: predicate scores result directly from the number of actual predicate evaluations.  Complex predicates generated by this technique are never truly evaluated, so their probability values would have little connection to actual program execution.  Whether this would affect their usefulness is unknown.

% LocalWords:  Dodoo Daikon's ccrypt DIDUCE DIDUCE's tvl
