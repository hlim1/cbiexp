Put name markers in brackets after items in the to-do list:

  +Foo: things Foo is best suited to work on or plans to work on
  -Foo: things Foo is definitely not able to work on
  *Foo: things Foo is working on right now

If you see a problem but either cannot fix it or don't want to work on
it now, add it to the list below so that it will not be overlooked or
forgotten.  Try to keep to-do items roughly organized by section,
except for whole-paper issues which are listed first.

As you fix outstanding items, remove them from the list and check in
this updated to-do list along with your changes.  When this list is
empty, that basically means we're done!


------------------------------------------------------------------------
--
--  Section 4
--

Section 4 offers some interesting ideas, though they aren't explored
or justified as fully as they could be.  I'm not convinced that
Definition 4.2 is working in the right direction.  If two predicates
are highly correlated according to this definition, doesn't that mean
they are nearly identical and therefore not especially interesting as
a pair?  I would have thought that an interesting pair predicates
would be ones with very little apparent connection in the PDG, but
which nonetheless are tightly connected in how they predict failures.
[+chen]

Choosing predicates with the smallest intersection of predecessor sets also 
relates well with the revised motivation for the metrics; the smaller 
the intersection, the easier it is for a programmer to search the 
code related to both predicates to find the connection.  By the current 
definition "highly correlated" predicate combinations are selected; 
this means a programmer has a potentially huge intersection set to
search through for the item which 1. connects the components and 
2. relates to the bug.

------------------------------------------------------------------------
--
--  Section 5
--

Section 5: I'm not sure that these are properly considered as
*internal* threats to validity, but I don't really know that taxonomy
of threat types very well.
[+Jake]


------------------------------------------------------------------------
--
--  Section 6
--

Section 6 presents some results with conjunctions and disjunctions
broken out, but not all.  I'd like to see that done with the rest,
such as for Figure 2, to see if there's anything interesting going on.
[-Ben] [*arumuga]

The first paragraph of Section 6.4 [Effect of Sampling Rate] claims
that the number of interesting conjunctions is comparable to the
number of interesting simple predicates even at 1/1000 sampling.  Is
that really true?  You can't tell by squinting at the plots, and I
cannot find these raw numbers anywhere in the "data/*.txt" files.
[*arumuga]

Several of the figures need layout or color-selection work, especially
for monochrome printing.  [*Ben]

However, I don't buy *either* explanation for the weird conjunction
behavior.  Offline downsampling is supposed to be applied before
binarization, not after.  Assuming you did that correctly, offline
downsampling gives numbers which are completely indistinguishable from
online sampling.  And just getting a weird run of numbers from your
random number generator is unlikely to show the same conjunction hump
in six different applications.
[*arumuga]

You also don't say anything about how long it takes to perform this
analysis.  Seconds?  Hours?  Weeks?  Readers will want to know.  This
is especially important considering that the conclusion mentions the
need to further reduce the computational complexity of the analysis.
[+Ben]

Section 6.1 [Top Scoring Predicates] no longer matches the data
actually shown in Figure 2.  We need to understand why the new Figure
2 doesn't look like the old one.  If the new figure is correct, the
discussion in Section 6.1 should be updated accordingly.

Figure 2 has relatively little information in it.  Perhaps this
one-bar plot should be replaced with either a small table or just
prose discussion with no table or figure at all.

As effort levels increase, several Siemens apps show slight
*decreases* in the number of interesting disjunctions.  This seems
incorrect.  Either our data is bad (i.e., we have a bug) or we are
misunderstanding something important.  We need to figure out what's
going on and fix or explain it.  [*arumuga]


------------------------------------------------------------------------
--
--  Section 8
--

Section 8 concludes on a weak note.  We ought to be able to make this
a bit sexier while still being honest about the technique's
limitations. [+Ben]
