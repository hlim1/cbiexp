% -*- TeX-master: "master" -*-

\section{Introduction}

Statistical debugging improves software quality by identifying program (mis)behaviors that are highly predictive of subsequent program failure.  As embodied in the Cooperative Bug Isolation Project (\emph{CBI}) \cite{Liblit:2004:CBI}, these techniques find bugs in programs by analyzing reports collected from software executing in the hands of end users.  First the CBI instrumenting compiler injects extra code that evaluates simple Boolean expressions (called \emph{predicates}) at various program points.  Predicates are designed to capture potentially interesting program behaviors such as results of function calls, directions of branches, or values of variables.  Upon termination of an instrumented program, a feedback report is generated that records how often each predicate was observed, and how often each was both observed and found to be true.  Given many such feedback reports, e.g., from a large user community, statistical debugging is used to find predicates that are predictive of failure \cite{Liblit:2005:SSBI,Zheng:2006:SDSIMB}.  These predicates are then ranked and presented to the developer.

CBI gathers execution reports by using valuable CPU cycles at end user machines.  It is essential to make those cycles worthwhile by extracting every bit of useful information from them.  However, current statistical analysis algorithms consider predicates in isolation from one another \cite{Liblit:2005:SSBI,Zheng:2006:SDSIMB}.  They overlook potentially useful relations between predicates.  Predicates are expressions involving program variables at different program points and hence may be related by control and data dependences.  We propose to capture these relations by building \emph{complex predicates} from the set of currently instrumented predicates (which we refer to as \emph{simple predicates}).  Since predicates are Boolean expressions, they are combined using logical operators (such as conjunction and disjunction).  We construct complex predicates and include them in the input to the statistical analysis algorithms.

There are two approaches to combine predicates using logical operators:
\begin{enumerate}
\item Change the instrumenting compiler to explicitly monitor each complex predicate at run time.
\item Estimate the value of each complex predicate from the values of its components.
\end{enumerate}

The first approach will yield a precise value but needs significant modifications to existing infrastructure.  The second approach will be less precise (as described later) but requires only few modifications to existing infrastructure (and none to the instrumenting compiler).  In the present work, we implement the second approach, which serves as a proof of concept for using complex predicates, as well as a justification for a future attempt at incorporating them into the compiler.

The remainder of this paper is organized as follows.  \autoref{sec-bground} reviews statistical debugging and motivates the present effort to find complex failure predictors.  \autoref{sec-complex-preds} gives a precise definition of complex predicates and discusses the trade-offs in our implementation.  \autoref{sec-metrics} defines two metrics to evaluate the usefulness of a complex predicate.  \autoref{sec-qual} discusses two case studies that demonstrate the usefulness of complex predicates.

\autoref{sec-experiments} presents the results of experiments conducted on a large suite of buggy test programs, including an assessment of the effect of sparse random sampling on complex predicates.  Sparse random sampling is a technique used by CBI to reduce the runtime overhead of instrumentation.  \autoref{sec-rw} discusses related work and \autoref{sec-conc} concludes.
