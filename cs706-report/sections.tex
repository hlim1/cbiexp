\section{Motivation}

The Cooperative Bug Isolation (CBI) Project~\cite{Liblit:2004:CBI} collects reports from software executing in the hands of end users.  These reports describe various program behaviors (predicates), such as results of function calls, directions of branches and values of variables.  Statistical analysis (~\cite{Liblit:2005:SSBI} and ~\cite{Zheng:2006:SDSIMB}) is used to find predicates that are predictive of failure.  These predicates are then summarized and a report is given to the developer.  CBI can find only those bugs that significantly alter the program behavior (predicates) it monitors.  In other words, to find arbitrary bugs, CBI should monitor equally complex predicates.  However, we can construct complex predicates by combining simple predicates using logical operators.  This can be helpful in two ways:
\begin{enumerate}
\item CBI's analysis of non-deterministic bugs will improve.  Non-deterministic bugs have two (or possibly more) causes: a defect and a trigger.  For e.g., a defect may be a null pointer assignment and the trigger may be the branch above the place where the pointer is dereferenced.  Neither the defect nor the trigger are good predictors by themselves.  The defect may be true but the program does not fail until the trigger is true and vice versa.  In such a case, the conjunction of the defect and trigger will be the best predictor of the bug.  (Note: For the null pointer example, a variant of scalar pairs, that compares a variable $v$ with other variables in scope every time $v$ is used, will detect that error.  However, this will increase the number of predicates by several orders)

\item A complex predicate will give more detail to the developer as it narrows down the possible program states.  For example, in TCAS version 1 (in the Siemens test suite), the bug involves replacing $a >= b$ by $a > b$\footnote{In the actual program, the predicates occur at lines 93 and 75 respectively in file tcas.c.  Here $a$ is the local variable Down\_Separation and $b$ is the scalar return value of function ALIM}.  Besides several other predicates, CBI analysis produces two predicates: `$a >= b$ is true' and `$a > b$ is false'.  Analysing the predicate counts reveals that the score of their conjunction will be higher than either one.  Moreover, the conjunction will imply the predicate `$a==b$ is true' which captures the failing case better than the individual predicates.
\end{enumerate}

\section{Proposal}
For this project, we propose to extend CBI to analyze predicates combined using logical operators.  A portion of this extension is already available because for every predicate, CBI also analyzes its negation.  We propose to extend CBI to analyze conjunctions of predicates.  Combined with negation, this can analyze any propositional formula of predicates.  To be more precise, we plan to derive the counts of conjunctions of predicates from the counts of individual predicates.  This derivation should be such that if the input counts are a fair sample of execution behavior, the derived counts should also be from a fair random sample.  The counts for conjunctions can now be considered as a predicate and analyzed using techniques in~\cite{Liblit:2005:SSBI} or~\cite{Zheng:2006:SDSIMB}.

Reducing the sampling rate to significantly below 100\% creates a new problem. With a sampling rate of 1/1000, a data set of one million executions will on average contain 1000 executions where a given predicate was observed; however, an arbitrary conjunction of any two predicates will have only one observed execution.  A possible solution is to use the observed behavior of P to predict its value in runs when it was not observed.  For e.g., if 25\% of the runs in which P was true crash, we could randomly set P to be true in 25\% of the failed runs in which P was not observed.  Or, we could uniformly assign a confidence of 0.25 that P will be true in a failed run in which it was not observed.  Both of these options will compute the same score for individual predicates but will give different scores when conjunctions are evaluated.  It is not clear whether one of the above options is better than the other.

$n$ predicates can be conjoined in $O(2^n)$ possible ways.  This exponential state space can be handled by pruning out the conjunction of two predicates if the conjunction has a lower score (as described in ~\cite{Liblit:2005:SSBI}) than the individual predicates.  Another issue is that a complex predicate may be harder for the programmer to understand than its components.  Even though we do not have empirical evidence about whether it is true or not, if it turns out to be true, we could attempt to find stricter lower bounds on when a conjunction is considered more interesting than its components.  Or, we could impose an upper bound on the size of the conjunctions.

\section{Implementation and Evaluation}
For our implementation, we plan to use the existing infrastructure as much as possible.  First, we will solve the problem assuming complete data collection (sampling rate = 100\%) and apply the analysis described in ~\cite{Liblit:2005:SSBI}.  This will give us an initial idea about the kind of results we can expect.  Then we can branch and do two things simultaneously.  First, the initial implementation will be extended to handle sampling rates $<$ 100\%.  Second, we would explore ways to quantify the programmer effort required to fix the bugs.  The approach described in~\cite{1062522} and ~\cite{renieris03fault} will not apply if we have a conjunction of predicates from different lines of the source code.  It assumes that the programmer will start at the predicate and explore the code\footnote{Actually, program dependence graph} near the predicate in a breadth first order.  With this assumption, the metric is defined as the percentage of code examined by BFS before the line with the bug is reached.  In a similar way, we could assume that given two predicates, the programmer will explore the shortest path connecting the two predicates.  If the bug is not identified, he will arbitrarily choose one predicate\footnote{the predicate that appears later in the PDG may be more applicable} and do a BFS.  Then, the metric would be the percentage of code examined in such an exploration.  We haven't identified the best metric yet, but this one appears reasonable and simple.  It has the property that it reduces to the existing metric if the two predicates are the same.

And, finally we could also evaluate the performance of the technique described in ~\cite{Zheng:2006:SDSIMB} in the presence of these complex predicates.  (Note: As noted in the schedule below, this is an optional part which we promise to do if we finish the other phases on time).  We are planning to use the Siemens suite for evaluating the effectiveness of predicate conjunctions.  Sparse sampling requires a large number of runs.  So, we plan to evaluate the solution in the face of sparse sampling on applications like ccrypt and bc that have the necessary infrastructure to generate random test inputs.

\section{Schedule}
{\bf Phase 1}: Initial implementation for the non-sampling scenario: \newline
\hspace*{5ex}Implementation: 1 week \newline
\hspace*{5ex}Gathering results: 1 week \newline
{\bf Estimated finish time: Nov. 10}

{\bf Phase 2}: \newline
(a) Handle Sampling: \newline
\hspace*{5ex}Implementation: 1 week \newline
\hspace*{5ex}Gathering results: 1 week \newline
(b) Identifying an evaluation metric: \newline
\hspace*{5ex}Estimated time: 2 weeks \newline
{\bf Estimated finish time: Nov.  24}

{\bf Phase 3}: Apply techniques in ~\cite{Zheng:2006:SDSIMB} or Buffer period for phases 1,2 \newline
\hspace*{5ex}Estimated time: 2 weeks \newline
{\bf Estimated finish time: Dec. 8}

{\bf Phase 4}: Report and Presentation

During phase 1 of the project, we must get familiar with the CBI implementation and test infrastructure.  So, we plan to do this together.  During phase 2, two of us will be doing the two tasks in parallel and the third member will take part in the problem that is more challenging at that point.

\section{Related Work}
Daikon~\cite{ErnstPGMPTX2006} detects invariants in a program by observing values computed by it.  It can compute complex invariants by combining program variables and operators like sum, max etc on collection (e.g. array) objects.  Invariants are predicates that must be true in correct executions.  ~\cite{ErnstDRAFT} extends the work to compute implications of the form a $\implies$ b.  Our project is different from this in two ways.  First, the data we have (bit vector of predicate counts) is different from what Daikon uses (values of variables at different points).  So the fundamental techniques in our approach and ~\cite{ErnstDRAFT} are different.  Secondly, our project also aims at processing a sparse random sample of predicate values, whereas ~\cite{ErnstPGMPTX2006} requires complete execution traces.  Diduce~\cite{581377} is inspired by Daikon and identifies predicates that are true in failed runs.  ~\cite{1081753} is a statistical debugging tool similar to CBI.  Both of these approaches does not try to construct complex predicates.
