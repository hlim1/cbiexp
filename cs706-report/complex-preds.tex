% -*- TeX-master: "report" -*-

\section{Complex Predicates}
\label{sec-complex-preds}
%         *         *         *         *         *         *        80 columns |
A complex predicate $C$ is defined as $C = \phi(p_1, p_2, \ldots p_k)$ where 
$p_1, p_2, \ldots p_k$ are simple predicates and $\phi$ is a function in 
conjunctive normal form (CNF).  Evaluating $C$ requires combining predicates 
using $\wedge$ (``and'') and $\vee$ (``or''); a negation operator is not required 
because by design, the negation of every CBI predicate $p$ is also a predicate.  
For $N$ predicates there are $2^{2^N}$ such Boolean functions 
\cite{MathWorld:BoolFuncs}.  There may be hundreds of simple predicates involved 
in the analysis, and so this a prohibitively large number.

To reduce complexity we consider only functions of two predicates.  Out of the
16 ($2^{2^2}$) such functions, we consider only conjunction and disjunction since
they are likely to be most easily understood by programmers.  Our revised
definition is $C = \phi(p_1, p_2)$ where $\phi \in \{\vee, \wedge\}$.  Conjunction
and disjunction are commutative, and the reflexive cases ($p_1 \wedge p_1$ and 
$p_1 \vee p_1$) are uninteresting.  This reduces the number of complex predicates
to just ${N \choose 2} = \frac{N (N-1)}{2}$ binary conjunctions and an equal number 
of binary disjunctions.  These may be evaluated for a set of $R$ runs in $O(R N^2)$ 
time.  The revised definition for a complex predicate is used throughout; related
definitions may be trivially extended to the general case.

\subsection{Measuring Complex Predicates}
\label{sec-measuring}

For a predicate $p$ and a run $R$, $R(p) = \true$ if and only if $p$ was observed to be true at least once during run $R$.  Similarly we could define $R(C)$ as follows:
\begin{defn}
\label{dfn1}
For a complex predicate $C = \phi(p_1, p_2)$, $R(C) \equiv \true$ iff at some point during the execution of the program, $C$ was observed to be true.
\end{defn}

The difficulty with this notion of complex predicates is that $C$ must be explicitly monitored during the program execution.  For example, if $C_1 = p_1 \wedge p_2$ then $R(p_1) = \true$ and $R(p_2) = \true$ does not imply that $R(C) = \true$.  $p_1$ and $p_2$ may be true at different stages of execution but never true at the same time.  Furthermore, when $p_1$ and $p_2$ appear at different source locations, there may be no single point in time at which both are even well-defined and therefore simultaneously observable.  In order to be able to estimate the value of $C$ from its components, we adapt a less time-sensitive definition as follows:
\begin{defn}
\label{dfn2}
For a complex predicate $C = \phi(p_1, p_2)$, $R(C) = \true$ iff $\phi(R(p_1), R(p_2)) = \true$
\end{defn}

In other words, we assume that $R$ is distributive over $\phi$, effectively removing the requirement that all $p_i$ be observed simultaneously.  This can lead to false positives, because $R(C)$ may be computed to $\true$ when it is actually $\false$ at all moments in time.  False negatives, however, cannot arise.  The impact of this assumption on the score of $C$ may be either positive or negative depending on whether $R$ failed or succeeded.

\subsection{Three Valued Logic}
\label{sec-tvl}
This section explains how conjunctions and disjunctions are actually computed.  Three-valued logic is used because the value of a predicate in a run may not be certain. This can arise in two situations:
\begin{enumerate}
\item The predicate was not observed in a run because the run did not reach the line where it was defined.
\item The program reached the line where the predicate was defined but was not observed because of sampling.
\end{enumerate}

%         *         *         *         *         *         *        80 columns |

In such a case, the value of a predicate $p$ is considered unknown.  For the 
analysis introduced in \autoref{sec-bground}, it is enough to consider whether 
$R(p)$ was $\true$ or $\neg \true$ (either $\false$ or $\unknown$).  When 
constructing compound predicates, however, considering the sub-cases of 
$\neg \true$ separately allows additional run information to be derived.  
Constructing a compound predicate requires generating two bits for each program
run: $R(C)$ and $\obs{R}{C}$.  The case where a compound predicate is observed but not
true can only be generated by considering whether the same was true for its
components.

Consider a complex predicate $C = p_1 \wedge p_2$.  If either $R(p_1)$ or $R(p_2)$ was $\false$ in a run $R$, then $R(C) = \false$ - one false value is sufficient to disprove a conjunction.  If both $R(p_1)$ and $R(p_2)$ were $\true$, then $C$ was observed to be $\true$.  Otherwise, the value of $R(C)$ is $\unknown$. This is shown using a three-valued truth table in \autoref{tab:and}.

Similarly one true value is sufficient to prove a disjunction, and so a disjunction is $\false$ only if its components were observed $\false$ and not $\unknown$.  The truth table for complex predicate $D = p_1 \vee p_2$ is shown in \autoref{tab:or}.

\begin{table}
  \caption{3-valued Truth Table for $C = p_1 \wedge p_2$}
  \label{tab:and}
  \centering
  \begin{tabular}{c|ccc}
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    $p_1 \diagdown p_2$ & T & F & ? \\
    \hline
    T & T & F & ? \\
    F & F & F & F \\
    ? & ? & F & ? \\
  \end{tabular}
\end{table}


\begin{table}
  \caption{3-valued Truth Table for $D = p_1 \vee p_2$}
  \label{tab:or}
  \centering
  \begin{tabular}{c|ccc}
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    $p_1 \diagdown p_2$ & T & F & ? \\
    \hline
    T & T & T & T \\
    F & T & F & ? \\
    ? & T & ? & ? \\
  \end{tabular}
\end{table}

\subsection{Interesting Complex Predicate}
Even using the revised definition for $C$ the number of complex predicates is still quadratic in the number of simple predicates.  A large number of complex predicates formed by this procedure are likely to be useless in the analysis of the program.  A complex predicate that has a lower score than one of its components is useless.  The component (simple) predicate with a higher score is a better predictor of failure, and so the complex predicate adds nothing to the analysis.

\begin{defn}
\label{dfn3}
A complex predicate $C = \phi(p_1, p_2)$ is ``interesting'' iff $\Importance(C) > \max(\Importance(p_1), \Importance(p_2))$
\end{defn}

In the case where the complex predicate has the same score as a component predictor, the simpler one is preferable.  Keeping only interesting combinations of predicates reduces the memory burden of storing them, and helps ensure the utility of a complex predicate that is presented to the user.

\subsection{Pruning}
\label{sec-pruning}
Constructing complex predicates from simple ones requires generating two bits of information (according to the three value logic discussed in \autoref{sec-tvl}) for each program run; as CBI is meant to analyze deployed software program runs potentially number in the hundreds of thousands, if not millions.  The measure of a complex predicate's relevance to a bug is its $\Importance$ score, which can only be derived once run information has been generated.  Complex predicates that are not \emph{interesting} provide no information useful in debugging and are not presented to the programmer; in such a case the effort to form the predicate has been wasted.  This provides the motivation to prune combinations before run information is generated based on an estimate of their resulting scores.  If this estimate falls below the threshold required for the predicate to be presented to the programmer, the complex predicate is not constructed.  Pruning predicates before they are constructed reduces a $O(R)$ operation (constructing run information) to one which executes in constant time.

The threshold $\Importance$ value, which complex predicates must potentially exceed to be constructed, can be calculated in two ways:
\begin{enumerate}
\item Only \emph{interesting} complex predicates are retained; for predicate $C = \phi(p_1, p_2)$ the threshold is $\max(\Importance(p_1), \Importance(p_2))$.
\item During redundancy elimination, only the predicate with the highest score is retained at each iteration.  The threshold is therefore the highest score yet seen (including those of simple predicates).
% Note: as of 12/06 our implementation didn't do this.  This may have changed with recent modifications...
\end{enumerate}

%         *         *         *         *         *         *        80 columns |
To simplify the formulae derived in this section, we introduce some new terms and
notations.  \obsFalse{R}{p} is the number of runs in which predicate $p$ was observed
at least once but never observed $\true$.  It is equal to $\obs{R}{p} - R(p)$.
$\ub{x}$ and $\lb{x}$ denote an upper bound and lower bound on quantity $x$
respectively.  

Using an upper bound as the estimate of $\Importance$ guarantees that no 
predicate is pruned erroneously.  This upper bound can be determined by maximizing
$\Increase(p)$ and $F(p)$ under constraints based on the propositional operation.
$\Importance(P)$ (\autoref{eqn2}), being a harmonic mean of these two terms, will
likewise be maximized.  From \autoref{eqn1}, an increase in $F(p)$ or $\obs{S}{p}$
or a decrease in $S(p)$ or $\obs{F}{p}$ will increase the value of $\Increase(p)$.
So an upper bound on $\Increase(p)$ would be:

\begin{equation}
\label{eqn3}
\ub{\Increase(p)} \equiv
\frac{\ub{F(p)}}{\lb{S(p)} + \ub{F(p)}}
-
\frac{\lb{\obs{F}{p}}}{\ub{\obs{S}{p}} + \lb{\obs{F}{p}}}
\end{equation}

Consider a conjunction $C = p_1 \wedge p_2$.  From \autoref{tab:and}, $C$ is
observed $\true$ if both $p_1$ and $p_2$ were observed $\true$.  i.e. the set
of runs in which $C$ was observed $\true$ is the intersection of the sets of
runs in which $p_1$ was observed $\true$ and $p_2$ was observed $\true$.  So
$R(C)$ cannot exceed either $R(p_1)$ or $R(p_2)$.  Thus,
\begin{equation}
  \ub{R(C)} = \min(R(p_1), R(p_2))
\end{equation}

Likewise, $R(C)$ is minimized when there is minimum overlap between the set
of runs in which $p_1$ was observed $\true$ and $p_2$ was observed $\true$.
The minimum overlap is $0$ as long as $R(p_1) + R(p_2)$ does not exceed $|R|$,
the total number of runs.  Otherwise, both $p_1$ and $p_2$ must be observed
together in at least $R(p_1) + R(p_2) - |R|$ runs.
\begin{equation}
  \lb{R(C)} = \max(0, R(p_1) + R(p_2) - |R|)
\end{equation}

Consider $\obs{R}{C}$.  $C$ is observed when
\begin{enumerate}
\item Both $p_1$ and $p_2$ are observed $\true$
\item Either $p_1$ or $p_2$ is observed $\false$
\end{enumerate}

Now, to maximize $\obs{R}{C}$, applications of both rules above should be
maximized.
There are $\min(R(p_1), R(p_2))$ applications of Rule 1 when the set 
of runs in which $p_1$ and $p_2$ are observed completely overlap.
There are $\obsFalse{R}{p_1} + \obsFalse{R}{p_2}$ applications of Rule
2 when the sets of runs in which $p_1$ and $p_2$ are observed $\false$ are
completely non-overlapping.

However, there has to be an overlap between these cases if their sum exceeds 
$|R|$, the total number of runs.  Thus,
\begin{equation}
  \ub{\obs{R}{C}} = \min(|R|, \obsFalse{R}{p_1} + \obsFalse{R}{p_2}
                   + \min(R(p_1), R(p_2)))
\end{equation}

Finally, to minimize $\obs{R}{C}$, applications of the two rules above are 
minimized.  This can happen when:
\begin{enumerate}
\item the $\false$ observations of $p_1$ and $p_2$ completely overlap, contributing
$\max(\obsFalse{R}{p_1}, \obsFalse{R}{p_2})$ to $\obs{R}{C}$
\item the $\true$ observations of $p_1$ and $p_2$ are completely non-overlapping.
However, the outcomes of $\min(\obsFalse{R}{p_1}, \obsFalse{R}{p_2})$ runs has
been fixed in the previous step reducing the number of effective runs to
$|R| - \min(\obsFalse{R}{p_1}, \obsFalse{R}{p_2})$.  Among these runs, $R(p_1) + R(p_2)$
runs must be selected non-overlappingly, failing which there would be an
$R(p_1) + R(p_2) - (|R| - \min(\obsFalse{R}{p_1}, \obsFalse{R}{p_2}))$ overlap
between the two sets.
\end{enumerate}

Thus,
\begin{eqnarray*}
  \lb{\obs{R}{C}} &=& \max(\obsFalse{R}{p_1}, \obsFalse{R}{p_2}) + \\
            & & \max(0, R(p_1) + R(p_2) - (|R| - \\
            & & \min(\obsFalse{R}{p_1}, \obsFalse{R}{p_2})))
\end{eqnarray*}

For simplicity and generality, the above discussion derives the bounds for a general 
set of runs $R$.  \autoref{tab:bounds-conj} lists the specific bounds required in
\autoref{eqn3} by considering the set of successful runs $S$ or the set of failed
runs $F$ instead of $R$.  In interest of space, we skip the derivation and just 
list the bounds for a disjunction $D = p_1 \vee p_2$ in \autoref{tab:bounds-disj}

\begin{table*}
  \caption{Bounds required in \autoref{eqn3} for a conjunction}
  \label{tab:bounds-conj}
  \centering
  \begin{tabular}{c|c}
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    Quantity & Bounds for $C = p_1 \wedge p_2$ \\
    \hline
    $\ub{F(C)} $
      &
      $\min(F(p_1), F(p_2))$
      \\      
    $\lb{S(C)}$
      &
      $\max(0, S(p_1) + S(p_2) - |S|)$
      \\
    $\lb{\obs{F}{C}}$
      &
      $\max(\obsFalse{F}{p_1}, \obsFalse{F}{p_2}) +
      \max(0, F(p_1) + F(p_2) - (|F| - \min(\obsFalse{F}{p_1}, \obsFalse{F}{p_2})))$
      \\
    $\ub{\obs{S}{C}}$
      &
      $\min(|S|, \obsFalse{S}{p_1} + \obsFalse{S}{p_2} + \min(S(p_1), S(p_2)))$
      \\    
  \end{tabular}
\end{table*}

\begin{table*}
  \caption{Bounds required in \autoref{eqn3} for a disjunction}
  \label{tab:bounds-disj}
  \centering
  \begin{tabular}{c|c}
    % after \\: \hline or \cline{col1-col2} \cline{col3-col4} ...
    Quantity & Bounds for $D = p_1 \vee p_2$ \\
    \hline
    $\ub{F(D)} $
      &
      $\min(|F|, F(p_1) + F(p_2))$
      \\      
    $\lb{S(D)}$
      &
      $\max(S(p_1), S(p_2))$
      \\
    $\lb{\obs{F}{D}}$
      &
      $\max(F(p_1), F(p_2)) + 
      \max(0, \obsFalse{F}{p_1} + \obsFalse{F}{p_2} - (|F| - \min(F(p_1), F(p_2))))$
      \\
    $\ub{\obs{S}{D}}$
      &
      $\min(|S|, S(p_1) + S(p_2) + \min(\obsFalse{S}{p_1}, \obsFalse{S}{p_2}))$
      \\    
  \end{tabular}
\end{table*}

As a concrete example, consider $C = p_1 \wedge p_2$.  Let us assume that there are $1000$
successful and failed runs and $p_1$ and $p_2$ are observed in all of these runs.
Furthermore, assume
$F(p_1) = 500$, $F(p_2) = 1000$, $S(p_1) = 250$ and $S(p_2) = 500$.
Substituting $\obsFalse{R}{p} = 1000 - R(p)$ and computing the bounds listed in
\autoref{tab:bounds} we get $\ub{F(C)} = 500, \lb{S(C)} = 0, \lb{\obs{F}{C}} = 1000$ and
$\ub{\obs{S}{C}} = 1000$.  As a result, the upper bound of $\Increase(C)$ will be 
$\frac{500}{500} - \frac{1000}{2000}=0.5$. Finally the upper bound of $\Importance(C)$ would be $\frac{2}{\frac{1}{0.5}+\frac{1}{log1000/log1000}} = 0.66$. 

Pruning complex predicates using the above calculations reduces the computational intensity of the analysis without affecting the results.  The effectiveness of pruning is examined in \autoref{sec-effectprune}.
