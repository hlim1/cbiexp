# @configure_input@

root ?= ../..
experiment ?= ..
name ?= $(error no name set)
datadir ?= $(experiment)/data
testsummaries := $(datadir)/summaries
corrdir := $(root)/correlations
tooldir := $(root)/src
srcdir ?= $(experiment)/src
raw-report-name ?= reports
matlab-counts ?= Xtru.sparse

xmlify-add-suffix := .html

time := /usr/bin/time
CXX := @CXX@
CPPFLAGS := @CPPFLAGS@ -I$(tooldir)
CXXFLAGS := @CXXFLAGS@ -W -Wall -Werror
LEXLIB := @LEXLIB@
HAVE_MEX = @HAVE_MEX@

ifeq ($(strip $(update-tools)),)
tool-deps =
else
tool-deps = $(addprefix $(tooldir)/, $(1))
endif

build = $(MAKE) update-tools=

sparsebase := fobs sobs ftr str
sparse := $(sparsebase:=.) $(sparsebase:=.ir) $(sparsebase:=.jc) $(sparsebase:=.meta)

schemes ?= all branches float-kinds g-object-unref returns scalar-pairs
sorts := lb is fs nf hl hs lbnf
projections := none #circular linear
views := $(foreach scheme, $(schemes), $(foreach sort, $(sorts), $(foreach projection, $(projections), $(scheme)_$(sort)_$(projection).xml)))
#topRho := $(foreach sort, hl hs, $(foreach proj, circular linear, top-rho_$(sort)_$(proj).xml))
zoom ?= all

find-zooms := find . -maxdepth 1 -name 'zoom-corrected-*.xml'

links :=					\
	$(extra-links)				\
	bug-o-meter.css				\
	bug-o-meter.dtd				\
	bug-o-meter.js				\
	bug-o-meter.xsl				\
	corrected-view.dtd			\
	corrected-view.xsl			\
	link-cell.css				\
	logo.css				\
	logo.xsl				\
	logreg.dtd				\
	logreg.xsl				\
	operand.dtd				\
	operands.xsl				\
	pred-scores.css				\
	pred-scores.dtd				\
	pred-scores.xsl				\
	predictor-info.dtd			\
	projected-view.dtd			\
	projected-view.xsl			\
	projections.dtd				\
	projections.xml				\
	rho.dtd					\
	rho.xsl					\
	schemes.dtd				\
	schemes.xml				\
	scores.css				\
	scores.dtd				\
	scores.xsl				\
	sorts.dtd				\
	sorts.xml				\
	summary.css				\
	summary.dtd				\
	summary.xsl				\
	view.css				\
	view.dtd				\
	view.xsl

corrected :=						\
	all_hl_corrected-exact-complete.xml		\
	all_hl_corrected-approximate-complete.xml

web :=						\
	$(corrected)				\
	$(links)				\
	$(topRho)				\
	$(views)				\
	$(web_extras)				\
	predictor-info.xml			\
	stamp-src				\
	summary.xml

ifdef COMPOUND
web += all_hl_corrected-exact-complete_complex.xml
endif

publish ?= $(HOME)/www/$(name)-new

all: $(web)
.PHONY: all

publish: $(web:%=$(publish)/%)
	$(find-zooms) -exec cp '{}' $(publish) ';'
.PHONY: publish

$(publish)/stamp-src: stamp-src
	rm -rf $(publish)/src
	cp -r src $< $(publish)

$(publish)/%: %
	[ -d $(@D) ] || mkdir $(@D)
	cp $< $@

stamp-src: $(call tool-deps, htmlify-sources)
	$(tooldir)/htmlify-sources $(srcdir)
	touch $@
CLEANFILES += stamp-src src

links: $(links)
$(links): %: $(call tool-deps, %)
	if [ -L $@ ]; then rm -f $@; fi
	cp $(tooldir)/$* $@
CLEANFILES += $(links)
.PHONY: links

predictor-info.xml: preds.txt static-site-info.so $(call tool-deps, xmlify-results)
	$(tooldir)/xmlify-results $(source-strip-prefixes:%=--strip-prefix=%) $(xmlify_results_flags)
	$(build) links
	xmllint --valid --noout $@
CLEANFILES += predictor-info.xml

ifdef HAVE_MEX
$(filter-out %_none.xml, $(views)): preds.txt rho.bin static-site-info.so $(call tool-deps, project)
	$(time) $(tooldir)/project --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) $(projected_view_flags)
	$(build) links
	xmllint --valid --noout $(filter-out %_none.xml, $(views))
CLEANFILES += $(filter-out %_none.xml, $(views))

$(topRho): top-rho_%: all_% rho.bin $(call tool-deps, top-rho)
	$(tooldir)/top-rho
	$(build) links
	xmllint --valid --noout $(topRho)
CLEANFILES += $(topRho)

rho.bin: $(corrdir)/readsp.mexglx calculate.m $(sparse)
	echo "fwrite(fopen('$@','w'), rho, 'double');" | $(time) matlab -nodisplay -nojvm -r calculate
	test -s $@
CLEANFILES += rho.bin mats

$(corrdir)/readsp.mexglx: force
	$(MAKE) -C $(@D) $(@F)

calculate.m: $(corrdir)/genMscript.pl $(sparsebase:=.meta)
	$(time) $< .
CLEANFILES += calculate.m

$(sparse): $(corrdir)/mhn2sparsemat.pl f.runs s.runs obs.txt tru.txt
	$(time) $< . .
	for goal in $(sparse); do test -r $$goal; done
CLEANFILES += $(sparse)
endif

all_hl_corrected-approximate-complete.xml: f.runs obs.txt tru.txt $(call tool-deps, corrective-ranking/approximate-complete)
	$(time) $(tooldir)/corrective-ranking/approximate-complete --zoom=$(zoom) --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) $(confidence:%=--confidence=%) $(corrected_view_flags)
	$(build) links
	xmllint --valid --noout $@
	$(find-zooms) -print0 | xargs --null --no-run-if-empty xmllint --valid --noout
CLEANFILES += all_hl_corrected-approximate-complete.xml

all_hl_corrected-exact-complete.xml elimination-clusters.txt: f.runs obs.txt tru.txt $(call tool-deps, corrective-ranking/exact-complete)
	$(time) $(tooldir)/corrective-ranking/exact-complete --zoom=$(zoom) --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) $(confidence:%=--confidence=%) $(corrected_view_flags)
	$(build) links
	xmllint --valid --noout all_hl_corrected-exact-complete.xml
	test -e elimination-clusters.txt
	$(find-zooms) -print0 | xargs --null --no-run-if-empty xmllint --valid --noout
CLEANFILES += all_hl_corrected-exact-complete.xml elimination-clusters.txt

clean::
	$(find-zooms) -exec rm '{}' ';'

all_hl_corrected-%_complex.xml: f.runs obs.txt tru.txt $(call tool-deps, corrective-ranking/%) pairs.txt
	$(time) $(tooldir)/corrective-ranking/$* --zoom=$(zoom) --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) $(confidence:%=--confidence=%) $(corrected_view_flags) --complex-preds
	$(build) links
	xmllint --valid --noout $@
	$(find-zooms) -print0 | xargs --null --no-run-if-empty xmllint --valid --noout
CLEANFILES += all_hl_corrected-exact-complete_complex.xml corrected-exact-complete_complex.txt
clean::
	$(find-zooms) -exec rm '{}' ';'

obs.txt tru.txt: $(stamp-decimate) preds.txt s.runs f.runs static-site-info.so $(call tool-deps, compute-obs-tru)
	$(time) $(tooldir)/compute-obs-tru --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir)
CLEANFILES += obs.txt tru.txt

$(filter %_none.xml, $(views)): preds.txt static-site-info.so $(call tool-deps, gen-views) pairs.txt
	$(build) links
	$(tooldir)/gen-views --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) $(schemes:%=--force-scheme=%) $(view_flags) $(if $(COMPOUND), --complex-preds)
	xmllint --valid --noout $(filter %_none.xml, $(views))
CLEANFILES += $(filter %_none.xml, $(views))
CLEANFILES += complex_hl_none.xml complex-info.xml complex_all.txt

#############################################################################
# Shared XML goals, i.e., XML goals on which many other goals are dependent
#############################################################################

summary.xml: preds.txt s.runs f.runs static-site-info.so $(call tool-deps, gen-summary)
	$(time) $(tooldir)/gen-summary --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) --source-directory=src $(confidence:%=--confidence=%) >$@
	$(build) links
	xmllint --valid --noout $@
CLEANFILES += summary.xml


#############################################################################
# Shared goals, i.e., goals on which many other goals are dependent
#############################################################################

static-site-info.so: %.so: %.cc
	$(LINK.cc) -shared -fpic -o $@ $<
CLEANFILES += static-site-info.so

static-site-info.cc: $(sites)
	$(tooldir)/applyTemplateToSites.py $(sites) $@ $(tooldir)/static_site_info.tmpl --filter=CppFilter
CLEANFILES += static-site-info.cc

f.runs s.runs: outcomes.txt
	$(tooldir)/genOutcomeIndices.py outcomes.txt f.runs s.runs
CLEANFILES += s.runs f.runs

preds.txt: s.runs f.runs static-site-info.so $(call tool-deps, prefilter)
	$(time) $(tooldir)/prefilter --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) $(confidence:%=--confidence=%)
CLEANFILES += preds.txt


#############################################################################
# Truth probability estimation
# Estimate truth probabilities for every predicate in preds.txt for every run
# using the algorithm in the ICML 2006 paper
#
# In theory, any analysis done only on the culled predicates in preds.txt
# could use the estimated truth probabilities as a starting point
#
# If omit-truth-probability-estimation flag is set do not estimate
# probabilties, just report actual values
#############################################################################
ifndef omit-truth-probability-estimation
parmstats.txt notp-parmstats.txt: $(stamp-decimate) s.runs f.runs preds.txt static-site-info.so $(call tool-deps, collect_parmstats)
	$(time) $(tooldir)/collect_parmstats --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) --sample-rates=rates.txt
CLEANFILES += parmstats.txt notp-parmstats.txt

parms.txt notp-parms.txt: parmstats.txt notp-parmstats.txt static-site-info.so $(call tool-deps, est_parms)
	$(time) $(tooldir)/est_parms
CLEANFILES += parms.txt notp-parms.txt est_parms.log

X.dat notX.dat : preds.txt parms.txt notp-parms.txt static-site-info.so $(call tool-deps, get_tp_weights)
	$(time) $(tooldir)/get_tp_weights --begin-runs=$(begin-runs) --end-runs=$(end-runs) --estimate-tps=true
else
X.dat notX.dat : preds.txt static-site-info.so
	$(time) $(tooldir)/get_tp_weights --begin-runs=$(begin-runs) --end-runs=$(end-runs) --estimate-tps=false
endif
CLEANFILES += X.dat notX.dat truX.dat trunotX.dat truFreq.dat trunotFreq.dat

#############################################################################
# For every site corresponding to a predicate in preds.txt yields a histogram
# of the number of times a predicate associated with the site is observed true
# in a run. Done separately for failing and for succeeding runs.
#############################################################################
prior-dist: fpriors.dat spriors.dat
fpriors.dat spriors.dat: s.runs f.runs preds.txt static-site-info.so $(call tool-deps, gather_prior_dist)
	$(time) $(tooldir)/gather_prior_dist --runs-directory=$(datadir) --begin-runs=$(begin-runs) --end-runs=$(end-runs)
CLEANFILES += fpriors.dat spriors.dat

#############################################################################
# For every predicate in preds.txt yields a histogram of the ratios of the
# counts of a predicate to its compliment in a given run.
# Done separately for failing and for succeeding runs.
#############################################################################
truth-dist: struthfreq.dat ftruthfreq.dat
struthfreq.dat ftruthfreq.dat: s.runs f.runs preds.txt static-site-info.so $(call tool-deps, gather_prior_truths)
	$(time) $(tooldir)/gather_prior_truths --runs-directory=$(datadir) --begin-runs=$(begin-runs) --end-runs=$(end-runs)
CLEANFILES += struthfreq.dat ftruthfreq.dat

#############################################################################
# SOBER analysis
# implementation of the SOBER algorithm on predicates in preds.txt
#############################################################################
sober: sober.xml sober.txt
sober.xml sober.txt: static-site-info.so preds.txt $(call tool-deps, calc_sober)
	$(build) links
	$(time) $(tooldir)/calc_sober --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) --xmltemplate-prefix=$(name)
	xmllint --valid --noout sober.xml
CLEANFILES += sober.xml sober.txt

#############################################################################
# Biclustering
# ICML 2006 algorithm for simultaneously clustering runs and predicates
#############################################################################

bicluster: bicluster_votes.xml bicluster_preds.xml final-votes.txt
bicluster_votes.xml bicluster_preds.xml final-votes.txt: preds.txt X.dat notX.dat $(call tool-deps, bicluster)
	$(build) links
	$(time) $(tooldir)/bicluster --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) --xmltemplate-prefix=$(name) --truth-probability-weights=X.dat --not-truth-probability-weights=notX.dat
	xmllint --valid --noout bicluster_votes.xml
CLEANFILES += bicluster_votes.xml bicluster_preds.xml final-votes.txt bicluster_votes.log list*.xml qualities.log notQualities.log

#############################################################################
# Logistic Regression --- early CBI analysis
# 1. Computes a set of interesting predicates into nonconst_preds.txt
# 2. Chops up all runs into a set of training runs and a validation set
# 3. Iteratively computes a predictor for failure and success
#    At each iteration
#        computes the value for every predicate's coefficient
#            and stores it in theta.txt
#            the intercept is indexed as -1, -1
#        stores the values for the last iteration in logreg.txt
#        stores the results of applying the logistic regression formula to
#            every training run in train_lls.txt
#        stores the results of applying the logistic regression formula to
#            every validation run in val_lls.txt
#        evaluates by calculating a confusion matrix on the results
#            of the prediction for every validation run and storing this
#            in confmat.txt
############################################################################
nonconst-preds: train.runs val.runs nonconst_preds.txt
train.runs val.runs nonconst_preds.txt : s.runs f.runs static-site-info.so $(call tool-deps, compute_nonconst_preds)
	$(time) $(tooldir)/compute_nonconst_preds --runs-directory=$(datadir) --begin-runs=$(begin-runs) --end-runs=$(end-runs)
CLEANFILES += train.runs val.runs nonconst_preds.txt


theta: theta.txt train_lls.txt val_lls.txt confmat.txt
theta.txt train_lls.txt val_lls.txt confmat.txt logreg.txt: train.runs val.runs nonconst_preds.txt static-site-info.so $(call tool-deps, train_utillog)
	$(time) $(tooldir)/train_utillog --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) --delta1=10.0 --delta2=2.0 --delta3=1.0
CLEANFILES += theta.txt train_lls.txt val_lls.txt confmat.txt logreg.txt

logreg.xml: %.xml: %.txt static-site-info.so $(call tool-deps, %)
	$(tooldir)/$* < $*.txt >$@
	$(build) links
	xmllint --valid --noout $@
CLEANFILES += logreg.xml


#############################################################################
# does K-means clustering of runs
############################################################################
clusters : f_nonconst_preds.txt kmeans_group.txt
f_nonconst_preds.txt kmeans_group.txt: static-site-info.so $(call tool-deps, cluster_runs) s.runs f.runs
	$(time) $(tooldir)/cluster_runs --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir) --nonconst-file=f_nonconst_preds.txt
CLEANFILES += f_nonconst_preds.txt kmeans_groups.txt

#############################################################################
# gathers some very simple statistics about a program's executions
# generates three files:
#   never-reached.txt
#   never-false.txt
#   never-true.txt
# see never-reached/README for more information
############################################################################
never-kinds := reached false true
nevers := $(never-kinds:%=never-%.txt)
$(nevers): $(stamp-decimate) f.runs static-site-info.so $(call tool-deps, never-reached/never-reached)
	$(tooldir)/never-reached/never-reached --begin-runs=$(begin-runs) --end-runs=$(end-runs) --runs-directory=$(datadir)
	for goal in $(nevers); do test -r $$goal; done
CLEANFILES += $(nevers)


##############################################################################
# generate lots of data files for input to pLSA analysis
# --- this data is all post culling, i.e., the only features are those that
#     appear in preds.txt
#
# the plsa algorithm itself could be run on complete data, but this
#     functionality was not implemented
##############################################################################

Xtru.sparse Xobs.sparse X.xml: preds.txt
	$(time) $(tooldir)/matlab/make-counts-matrix --runs-directory=$(datadir) --begin-runs=$(begin-runs) --end-runs=$(end-runs)
CLEANFILES += Xtru.sparse Xobs.sparse X.xml

prerunsinfo.mat: outcomes.txt X.xml $(matlab-counts)
	$(time) matlab -nodisplay -r "path('$(tooldir)/matlab', path); convertData('$(matlab-counts)', 'prerunsinfo.mat', 'outcomes.txt', 'causes.txt', 'X.xml'); quit()"
CLEANFILES += prerunsinfo.mat

runsinfo.mat: prerunsinfo.mat
	test process.xml || $(time) xmllint --valid --noout process.xml
	$(time) matlab -nodisplay -r "path('$(tooldir)/matlab', path); path(pwd, path); postProcess('$<', '$@', 'process.xml'); quit()"
CLEANFILES += runsinfo.mat

runsinfo.dat: runsinfo.mat
	$(time) matlab -nodisplay -r "path('$(tooldir)/matlab', path); toDAformat('$<', '$@'); quit()"
CLEANFILES += runsinfo.dat

########################################################################


ifneq ($(strip $(update-tools)),)
$(tooldir)/%:

$(tooldir)/analysis-rules.mk: force
	$(MAKE) -C $(tooldir)
endif

clean::
	rm -rf $(CLEANFILES)
.PHONY: clean

force:
.PHONY: force

.DELETE_ON_ERROR:

########################################################################
pairs.txt: preds.txt
ifdef COMPOUND
	(cd .. && ln -sf analysis/static-site-info.so analysis/preds.txt .)
	csurf -nogui ../$(program).exe.prj -l $(tooldir)/effort/effort.stk
else
	touch pairs.txt
endif
CLEANFILES += pairs.txt
